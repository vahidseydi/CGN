{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FewShot+ActiveL.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/vahidseydi/CGN/blob/main/GCN.ipynb",
      "authorship_tag": "ABX9TyPy/lPWuLJTlWEf8RGecgqv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vahidseydi/CGN/blob/main/FewShot%2BActiveL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQrGTMcwGbkt"
      },
      "source": [
        "#Downloading dataset file from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnHBK6RWuN9j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "283e6699-a689-4a65-cb8c-f5debc688e84"
      },
      "source": [
        "#ابتدا دیتاست موجود در فولدر دیتا در آدرس گیت هاب پروژه، را در این نوت بوک دخیره می کنیم\n",
        "! wget 'https://github.com/vahidseydi/CGN/blob/main/Data/amazon_electronics_computers%20(1).npz?raw=true'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-23 14:12:27--  https://github.com/vahidseydi/CGN/blob/main/Data/amazon_electronics_computers%20(1).npz?raw=true\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/vahidseydi/CGN/raw/main/Data/amazon_electronics_computers%20(1).npz [following]\n",
            "--2021-05-23 14:12:27--  https://github.com/vahidseydi/CGN/raw/main/Data/amazon_electronics_computers%20(1).npz\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/vahidseydi/CGN/main/Data/amazon_electronics_computers%20(1).npz [following]\n",
            "--2021-05-23 14:12:27--  https://raw.githubusercontent.com/vahidseydi/CGN/main/Data/amazon_electronics_computers%20(1).npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 31921488 (30M) [application/octet-stream]\n",
            "Saving to: ‘amazon_electronics_computers (1).npz?raw=true.5’\n",
            "\n",
            "amazon_electronics_ 100%[===================>]  30.44M  96.8MB/s    in 0.3s    \n",
            "\n",
            "2021-05-23 14:12:28 (96.8 MB/s) - ‘amazon_electronics_computers (1).npz?raw=true.5’ saved [31921488/31921488]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INK67X5IGkkc"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MYbUcRVdtDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37a4f0ed-c243-4cd3-a5bf-c658488365c9"
      },
      "source": [
        "import numpy as np\n",
        "#فایل های موجود در دیتاست را می خوانیم\n",
        "npz_data=np.load('/content/amazon_electronics_computers (1).npz?raw=true')\n",
        "npz_data.files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['adj_data',\n",
              " 'adj_indices',\n",
              " 'adj_indptr',\n",
              " 'adj_shape',\n",
              " 'attr_data',\n",
              " 'attr_indices',\n",
              " 'attr_indptr',\n",
              " 'attr_shape',\n",
              " 'labels',\n",
              " 'class_names']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmNiWW8bd-Xx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e5abe38-9639-49ca-e8bd-826fbe3c8f51"
      },
      "source": [
        "#کلاس های موجود در دیتاست شامل 10 کلاس می باشد\n",
        "class_names =npz_data['class_names']\n",
        "class_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Desktops', 'Data Storage', 'Laptops', 'Monitors',\n",
              "       'Computer Components', 'Video Projectors', 'Routers', 'Tablets',\n",
              "       'Networking Products', 'Webcams'], dtype='<U19')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFpxP_MNMmCX"
      },
      "source": [
        "#تابع زیر برای جداسازی داده های آموزش، تست و اعتبارسنجی استفاده می شود\n",
        "#برابر با تمام داده ها می باشد y\n",
        "labels =npz_data['labels']\n",
        "y=labels.size\n",
        "#p for calculating percentage for idx_train,val,test\n",
        "p = lambda x: x*y/100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9NewBDvWAdE"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch\n",
        "from scipy.sparse import  csr_matrix\n",
        "\n",
        "\n",
        "def load_data():\n",
        " \n",
        " features = sp.csr_matrix((npz_data['attr_data'], npz_data['attr_indices'], npz_data['attr_indptr']),shape=npz_data['attr_shape'])\n",
        "\n",
        " # build graph\n",
        " \n",
        " adj= sp.csr_matrix(sp.csr_matrix((npz_data['adj_data'], npz_data['adj_indices'], npz_data['adj_indptr']),shape=npz_data['adj_shape']))\n",
        " \n",
        " # build symmetric adjacency matrix\n",
        "\n",
        " adj = adj + adj.T.multiply(adj.T > adj) - adj.multiply(adj.T > adj)\n",
        " adj = normalize(adj + sp.eye(adj.shape[0]))\n",
        " #اول اعداد 0 و 1 هست بعد از نرمالایز تغییر میکند \n",
        "\n",
        " labels=npz_data['labels']\n",
        " #لیبل ها را یکی اضافه می کنیم تا لیبل 0 را به داده های بدون لیبل دهیم\n",
        " labels=labels+1\n",
        "\n",
        " #جداسازی داده ها \n",
        " idx_train =range(round(p(70)))\n",
        " idx_val = range(idx_train[-1],idx_train[-1]+round(p(15)))\n",
        " idx_test =range(idx_val[-1],idx_val[-1]+round(p(15)))\n",
        "\n",
        " idx_train = torch.LongTensor(idx_train)\n",
        " idx_val = torch.LongTensor(idx_val)\n",
        " idx_test = torch.LongTensor(idx_test)\n",
        "\n",
        " features = torch.FloatTensor(np.array(features.todense()))\n",
        " adj = torch.FloatTensor(np.array(adj.todense()))\n",
        " labels = torch.LongTensor(labels)\n",
        "\n",
        "\n",
        " return adj, features, labels, idx_train, idx_val, idx_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9YheZ8yNTSL"
      },
      "source": [
        "def normalize(mx):\n",
        "    \"\"\"Row-normalize sparse matrix\"\"\"\n",
        "    rowsum = np.array(mx.sum(1))\n",
        "    #sum in every row \n",
        "    r_inv = np.power(rowsum, -1).flatten()\n",
        "    # every sum to the power of -1 \n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    #diagonal matrice \n",
        "    mx = r_mat_inv.dot(mx)\n",
        "    return mx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iha5MQaYDJpG"
      },
      "source": [
        "def accuracy(output, labels):\n",
        "    preds = output.max(1)[1].type_as(labels)\n",
        "    correct = preds.eq(labels).double()\n",
        "    correct = correct.sum()\n",
        "    return correct / len(labels)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQLBOry4WJvV"
      },
      "source": [
        "adj, features, labels, idx_train, idx_val, idx_test = load_data()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsHyFUvEUMFQ"
      },
      "source": [
        "\n",
        "\n",
        "#Constructing Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0-99ajritPS"
      },
      "source": [
        "#20% of train data for labeled\n",
        "#80% of train data for unlabeled\n",
        "#جداسازی داده های با لیبل و بدون لیبل برای آموزش \n",
        "\n",
        "p_train = lambda x: x*len(idx_train)/100\n",
        "\n",
        "idx_labeled_train =range(round(p_train(20)))\n",
        "idx_unlabeled_train = range(idx_labeled_train[-1],idx_labeled_train[-1]+round(p_train(80)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUovgcgTOAmt",
        "outputId": "0ce2698d-e898-4459-867e-b23ef1d87d10"
      },
      "source": [
        "print(idx_labeled_train,idx_unlabeled_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(0, 1925) range(1924, 9625)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6003R_bp4Xkz"
      },
      "source": [
        "#اندیس مربوط به هر کلاسی را جدا می کنیم\n",
        "class_1 =[]\n",
        "class_2 =[]\n",
        "class_3 =[]\n",
        "class_4 =[]\n",
        "class_5 =[]\n",
        "class_6 =[]\n",
        "class_7 =[]\n",
        "class_8 =[]\n",
        "class_9 =[]\n",
        "class_10=[]\n",
        "class_1=[i for i,x in enumerate(labels[idx_labeled_train]) if x==1] \n",
        "class_2=[i for i,x in enumerate(labels[idx_labeled_train]) if x==2] \n",
        "class_3=[i for i,x in enumerate(labels[idx_labeled_train]) if x==3]\n",
        "class_4=[i for i,x in enumerate(labels[idx_labeled_train]) if x==4] \n",
        "class_5=[i for i,x in enumerate(labels[idx_labeled_train]) if x==5] \n",
        "class_6=[i for i,x in enumerate(labels[idx_labeled_train]) if x==6] \n",
        "class_7=[i for i,x in enumerate(labels[idx_labeled_train]) if x==7] \n",
        "class_8=[i for i,x in enumerate(labels[idx_labeled_train]) if x==8] \n",
        "class_9=[i for i,x in enumerate(labels[idx_labeled_train]) if x==9] \n",
        "class_10=[i for i,x in enumerate(labels[idx_labeled_train]) if x==10] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unaiIobt6ExB",
        "outputId": "42311852-a20e-4309-c296-deb41cdb7413"
      },
      "source": [
        "#class_10"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20,\n",
              " 132,\n",
              " 136,\n",
              " 326,\n",
              " 355,\n",
              " 357,\n",
              " 385,\n",
              " 397,\n",
              " 428,\n",
              " 479,\n",
              " 502,\n",
              " 583,\n",
              " 592,\n",
              " 795,\n",
              " 836,\n",
              " 845,\n",
              " 847,\n",
              " 891,\n",
              " 914,\n",
              " 1007,\n",
              " 1087,\n",
              " 1129,\n",
              " 1196,\n",
              " 1250,\n",
              " 1273,\n",
              " 1353,\n",
              " 1401,\n",
              " 1445,\n",
              " 1503,\n",
              " 1797,\n",
              " 1818,\n",
              " 1835,\n",
              " 1850,\n",
              " 1869]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1Sok0uo6Igw",
        "outputId": "765b8129-7fb2-40e0-e382-14ce7943fc24"
      },
      "source": [
        "labels[583]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DEj19oZ9yVr"
      },
      "source": [
        "#می خواهیم از هر کلاسی به صورت رندوم سمپل انتخاب کنیم\n",
        "import random\n",
        "Random_idx_train=[]\n",
        "#با تعداد شات تعیین می کنیم که از هر کلاس چند سمپل نیاز داریم\n",
        "N_shot=10\n",
        "for i in range(N_shot):\n",
        "  Random_idx_train.append(random.choice(class_1))\n",
        "  Random_idx_train.append(random.choice(class_2))\n",
        "  Random_idx_train.append(random.choice(class_3))\n",
        "  Random_idx_train.append(random.choice(class_4))\n",
        "  Random_idx_train.append(random.choice(class_5))\n",
        "  Random_idx_train.append(random.choice(class_6))\n",
        "  Random_idx_train.append(random.choice(class_7))\n",
        "  Random_idx_train.append(random.choice(class_8))\n",
        "  Random_idx_train.append(random.choice(class_9))\n",
        "  Random_idx_train.append(random.choice(class_10))\n",
        "\n",
        "#Random_idx_train#اندیس "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1_KllTImV3U"
      },
      "source": [
        "#اگر بخواهیم از هر کلاس یک سمپل انتخاب کنیم مجموعا 10 سمپل با لیبل داریم \n",
        "#اگر بخواهیم نسبت 20 به 80 را رعایت کنیم پس لازم است 40 داده بدون لیبل هم انتخاب کنیم\n",
        "\n",
        "hiddenIndex_train=[]\n",
        "\n",
        "for i in range(40*N_shot):\n",
        "  hiddenIndex_train.append(random.choice(idx_unlabeled_train))\n",
        "#hiddenIndex_train  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1C808icQZ2u_"
      },
      "source": [
        "#مجموع اندیس های آموزش شامل اندیس های زیر می باشد:\n",
        "#traindata_idx=Random_idx_train+hiddenIndex_train\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRhvyy9HgXT-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be24433e-d127-41ed-ce1c-ee8e9dfbdc9d"
      },
      "source": [
        "#labels_train_hidden:\n",
        "#تمام لیبل ها حتی هیدن ها،برای استفاده در اکتیولرنینگ\n",
        "labels_train_hidden=torch.hstack((labels[Random_idx_train],labels[hiddenIndex_train]))\n",
        "labels_train_hidden.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SkfjGpTMeVw"
      },
      "source": [
        "#labels_train_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OE8yFZhkFvI",
        "outputId": "3f52b2ae-8740-42e0-ff99-4b9d9e61ed15"
      },
      "source": [
        "labels[Random_idx_train]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  1,  2,  3,  4,  5,  6,  7,  8,\n",
              "         9, 10,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  1,  2,  3,  4,  5,  6,\n",
              "         7,  8,  9, 10,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  1,  2,  3,  4,\n",
              "         5,  6,  7,  8,  9, 10,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,  1,  2,\n",
              "         3,  4,  5,  6,  7,  8,  9, 10,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10,\n",
              "         1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOr1K7YJm7td"
      },
      "source": [
        "#labels[Random_idx_train]==labels_train_hidden[0:10*N_shot]\n",
        "#labels[hiddenIndex_train]==labels_train_hidden[10*N_shot:10*N_shot*4+10*N_shot]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo58EqipMk_m"
      },
      "source": [
        "#labels_train=labels_train_hidden\n",
        "#با توجه به اینکه از هر کلاس چند تا سمپل انتخاب کردیم از شماره آخری بقیه مربوط به هیدن ها میشود که صفر میذاریم\n",
        "#labels_train[10*N_shot+1:]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btpV4dc2Mnyc"
      },
      "source": [
        "#labels_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt6_cLWoMsTH"
      },
      "source": [
        "#labels_train_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7Lwde1zkTe9"
      },
      "source": [
        "labels_train=labels_train_hidden.detach().clone()\n",
        "#با توجه به اینکه از هر کلاس چند تا سمپل انتخاب کردیم از شماره آخری بقیه مربوط به هیدن ها میشود که صفر میذاریم\n",
        "labels_train[10*N_shot:]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU2yK_3RM6Cl"
      },
      "source": [
        "#labels_train_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EteMi10CkrbR"
      },
      "source": [
        "#labels_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiNVOiOZf9OM",
        "outputId": "027da643-04e6-494f-9398-e8ce3aabfbdf"
      },
      "source": [
        "#ایجاد ماتریس ویژگی ها از داده های با لیبل و بدون لیبل\n",
        "features_train=torch.vstack((features[Random_idx_train],features[hiddenIndex_train]))\n",
        "features_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500, 767])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6bLiV3Ynb0l",
        "outputId": "17a7e4e9-9925-498e-cff4-6502f80056f0"
      },
      "source": [
        "features_train[0:10*N_shot]==features[Random_idx_train]\n",
        "features_train[10*N_shot:10*N_shot*4+10*N_shot]==features[hiddenIndex_train]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        ...,\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28I52FrOiii1"
      },
      "source": [
        "#adj[1:10*N_shot,1:10*N_shot].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4x-xGrv0Sw0"
      },
      "source": [
        "#ایجاد ماتریس مجاورت از داده های با لیبل و بدون لیبل\n",
        "adj_train=torch.vstack((adj[Random_idx_train],adj[hiddenIndex_train]))\n",
        "\n",
        "for i in hiddenIndex_train :\n",
        "    Random_idx_train.append(i)\n",
        "    \n",
        "#ایجاد تقارن در ماتریس مجاورت\n",
        "adj_train=adj_train[0:10*N_shot*4+10*N_shot,Random_idx_train]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7_IwfbRKIt_"
      },
      "source": [
        "#adj_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kerWgiRDBcDP"
      },
      "source": [
        "#Random_idx_train[2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCpOOU5-83cf"
      },
      "source": [
        "#adj[717].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4yLSWzV83Z6"
      },
      "source": [
        "#adj_train[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08hYvuat7Z5w"
      },
      "source": [
        "#adj[782,782]\n",
        "#adj[30,30]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elrp9c9FTi2w"
      },
      "source": [
        "#Constructing Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jorUo0cyTv7o"
      },
      "source": [
        "##داده های تست و اعتبارسنجی نیز دقیقا مشابه داده های آموزش ایجاد می شوند##\n",
        "\n",
        "#20% of test data for labeled\n",
        "#80% of test data for unlabeled\n",
        "\n",
        "p_test = lambda x: x*len(idx_test)/100\n",
        "\n",
        "idx_labeled_test =range(round(p_test(20)))\n",
        "idx_unlabeled_test = range(idx_labeled_test[-1],idx_labeled_test[-1]+round(p_test(80)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZR91mjVTv7q",
        "outputId": "9c8e0d70-fb72-4881-8554-f468d98d0996"
      },
      "source": [
        "print(idx_labeled_test,idx_unlabeled_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(0, 413) range(412, 2062)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRdkBXRUTv7s"
      },
      "source": [
        "#اندیس مربوط به هر کلاسی را جدا می کنیم\n",
        "class_1 =[]\n",
        "class_2 =[]\n",
        "class_3 =[]\n",
        "class_4 =[]\n",
        "class_5 =[]\n",
        "class_6 =[]\n",
        "class_7 =[]\n",
        "class_8 =[]\n",
        "class_9 =[]\n",
        "class_10=[]\n",
        "\n",
        "class_1 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==1] \n",
        "class_2 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==2] \n",
        "class_3 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==3]\n",
        "class_4 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==4] \n",
        "class_5 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==5] \n",
        "class_6 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==6] \n",
        "class_7 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==7] \n",
        "class_8 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==8] \n",
        "class_9 =[i for i,x in enumerate(labels[idx_labeled_test]) if x==9] \n",
        "class_10=[i for i,x in enumerate(labels[idx_labeled_test]) if x==10] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sx8QozEI6WyU",
        "outputId": "6c48eeb1-5fc0-48f0-814a-662774420fdd"
      },
      "source": [
        "print(class_3 , labels[48])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[22, 29, 37, 48, 50, 57, 68, 72, 73, 87, 92, 106, 113, 125, 129, 131, 135, 149, 157, 190, 199, 207, 223, 226, 231, 241, 252, 254, 262, 277, 302, 309, 311, 318, 321, 322, 324, 325, 338, 359, 364, 367, 376, 393, 403] tensor(3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61JWi16l6zM3",
        "outputId": "c199eec1-a235-46ac-a8e5-12d7339642d6"
      },
      "source": [
        "type(class_1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AE5Sw2ZTv7t"
      },
      "source": [
        "# از هر کلاسی بتوانیم به صورت رندوم سمپل انتخاب کنیم\n",
        "import random\n",
        "Random_idx_test=[]\n",
        "\n",
        "for i in range(N_shot):\n",
        "  Random_idx_test.append(random.choice(class_1))\n",
        "  Random_idx_test.append(random.choice(class_2))\n",
        "  Random_idx_test.append(random.choice(class_3))\n",
        "  Random_idx_test.append(random.choice(class_4))\n",
        "  Random_idx_test.append(random.choice(class_5))\n",
        "  Random_idx_test.append(random.choice(class_6))\n",
        "  Random_idx_test.append(random.choice(class_7))\n",
        "  Random_idx_test.append(random.choice(class_8))\n",
        "  Random_idx_test.append(random.choice(class_9))\n",
        "  Random_idx_test.append(random.choice(class_10))\n",
        "\n",
        "#Random_idx_test#اندیس "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv7SWldYTv7u"
      },
      "source": [
        "#اگر بخواهیم از هر کلاس یک سمپل انتخاب کنیم مجموعا 10 سمپل با لیبل داریم \n",
        "#اگر بخواهیم نسبت 20 به 80 را ارعایت کنیم پس لازم است 40 داده بدون لیبل هم انتخاب کنیم\n",
        "\n",
        "hiddenIndex_test=[]\n",
        "\n",
        "for i in range(40*N_shot):\n",
        "  hiddenIndex_test.append(random.choice(idx_unlabeled_test))\n",
        "#hiddenIndex_test "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDcysoakTv7v",
        "outputId": "0233d51d-d939-49d0-e597-715956a039cb"
      },
      "source": [
        "labels_test_hidden=torch.hstack((labels[Random_idx_test],labels[hiddenIndex_test]))\n",
        "labels_test_hidden.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRnuyYHiTv7w"
      },
      "source": [
        "labels_test=labels_test_hidden.detach().clone()\n",
        "#با توجه به اینکه از هر کلاس چند تا سمپل انتخاب کردیم از شماره آخری بقیه مربوط به هیدن ها میشود که صفر میذاریم\n",
        "labels_test[10*N_shot:]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ICA7fEEztv"
      },
      "source": [
        "#labels_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWejgHLyE3qT"
      },
      "source": [
        "#labels_test_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtqi7LwXTv7x",
        "outputId": "92f27025-7ecc-4d8d-eecd-3fec58bd72dd"
      },
      "source": [
        "features_test=torch.vstack((features[Random_idx_test],features[hiddenIndex_test]))\n",
        "features_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500, 767])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnW1mVA5Tv7y",
        "outputId": "42eb0bf5-53b4-4385-dbf2-06d8c20b7624"
      },
      "source": [
        "features_test[0:10*N_shot]==features[Random_idx_test]\n",
        "features_test[10*N_shot:10*N_shot*4+10*N_shot]==features[hiddenIndex_test]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        ...,\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3CLd-KVTv7z"
      },
      "source": [
        "adj_test=torch.vstack((adj[Random_idx_test],adj[hiddenIndex_test]))\n",
        "\n",
        "for i in hiddenIndex_test :\n",
        "    Random_idx_test.append(i)\n",
        "\n",
        "adj_test=adj_test[0:10*N_shot*4+10*N_shot,Random_idx_test]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyz6oDB6Yyuf"
      },
      "source": [
        "#Constructing Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRkhidE6YWTu"
      },
      "source": [
        "#20% of val data for labeled\n",
        "#80% of val data for unlabeled\n",
        "\n",
        "p_val = lambda x: x*len(idx_val)/100\n",
        "\n",
        "idx_labeled_val =range(round(p_val(20)))\n",
        "idx_unlabeled_val = range(idx_labeled_val[-1],idx_labeled_val[-1]+round(p_val(80)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqHcKhKYYWTw",
        "outputId": "6d9dfb34-b605-41a9-d9d3-6315d807dd67"
      },
      "source": [
        "print(idx_labeled_val,idx_unlabeled_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "range(0, 413) range(412, 2062)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hR67HnajYWUE"
      },
      "source": [
        "#اندیس مربوط به هر کلاسی را جدا می کنیم\n",
        "class_1 =[]\n",
        "class_2 =[]\n",
        "class_3 =[]\n",
        "class_4 =[]\n",
        "class_5 =[]\n",
        "class_6 =[]\n",
        "class_7 =[]\n",
        "class_8 =[]\n",
        "class_9 =[]\n",
        "class_10=[]\n",
        "\n",
        "class_1=[i for i,x in enumerate(labels[idx_labeled_val]) if x==1] \n",
        "class_2=[i for i,x in enumerate(labels[idx_labeled_val]) if x==2] \n",
        "class_3=[i for i,x in enumerate(labels[idx_labeled_val]) if x==3]\n",
        "class_4=[i for i,x in enumerate(labels[idx_labeled_val]) if x==4] \n",
        "class_5=[i for i,x in enumerate(labels[idx_labeled_val]) if x==5] \n",
        "class_6=[i for i,x in enumerate(labels[idx_labeled_val]) if x==6] \n",
        "class_7=[i for i,x in enumerate(labels[idx_labeled_val]) if x==7] \n",
        "class_8=[i for i,x in enumerate(labels[idx_labeled_val]) if x==8] \n",
        "class_9=[i for i,x in enumerate(labels[idx_labeled_val]) if x==9] \n",
        "class_10=[i for i,x in enumerate(labels[idx_labeled_val]) if x==10] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9H3cAsQYWUF"
      },
      "source": [
        "# از هر کلاسی بتوانیم به صورت رندوم سمپل انتخاب کنیم\n",
        "import random\n",
        "Random_idx_val=[]\n",
        "\n",
        "for i in range(N_shot):\n",
        "  Random_idx_val.append(random.choice(class_1))\n",
        "  Random_idx_val.append(random.choice(class_2))\n",
        "  Random_idx_val.append(random.choice(class_3))\n",
        "  Random_idx_val.append(random.choice(class_4))\n",
        "  Random_idx_val.append(random.choice(class_5))\n",
        "  Random_idx_val.append(random.choice(class_6))\n",
        "  Random_idx_val.append(random.choice(class_7))\n",
        "  Random_idx_val.append(random.choice(class_8))\n",
        "  Random_idx_val.append(random.choice(class_9))\n",
        "  Random_idx_val.append(random.choice(class_10))\n",
        "\n",
        "#Random_idx_val#اندیس "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eRUuhJqYWUH"
      },
      "source": [
        "#اگر بخواهیم از هر کلاس یک سمپل انتخاب کنیم مجموعا 10 سمپل با لیبل داریم \n",
        "#اگر بخواهیم نسبت 20 به 80 را ارعایت کنیم پس لازم است 40 داده بدون لیبل هم انتخاب کنیم\n",
        "\n",
        "hiddenIndex_val=[]\n",
        "\n",
        "for i in range(40*N_shot):\n",
        "  hiddenIndex_val.append(random.choice(idx_unlabeled_val))\n",
        "#hiddenIndex_val "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGJZ-_e4YWUI",
        "outputId": "a1b7586b-793b-46ab-87b4-eef42fb3d26c"
      },
      "source": [
        "labels_val_hidden=torch.hstack((labels[Random_idx_val],labels[hiddenIndex_val]))\n",
        "labels_val_hidden.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEhEarXCYWUI"
      },
      "source": [
        "labels_val=labels_val_hidden.detach().clone()\n",
        "#با توجه به اینکه از هر کلاس چند تا سمپل انتخاب کردیم از شماره آخری بقیه مربوط به هیدن ها میشود که صفر میذاریم\n",
        "labels_val[10*N_shot:]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F00cnT2YWUJ",
        "outputId": "3851eddd-575a-4ebd-fc29-f211c7d3c1da"
      },
      "source": [
        "features_val=torch.vstack((features[Random_idx_val],features[hiddenIndex_val]))\n",
        "features_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500, 767])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oHe-7abYWUK",
        "outputId": "60cf4c93-a97c-47da-d28e-7288a69b07d1"
      },
      "source": [
        "features_val[0:10*N_shot]==features[Random_idx_val]\n",
        "features_val[10*N_shot:10*N_shot*4+10*N_shot]==features[hiddenIndex_val]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        ...,\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True],\n",
              "        [True, True, True,  ..., True, True, True]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJhiH9xIYWUL"
      },
      "source": [
        "adj_val=torch.vstack((adj[Random_idx_val],adj[hiddenIndex_val]))\n",
        "\n",
        "for i in hiddenIndex_val :\n",
        "    Random_idx_val.append(i)\n",
        "\n",
        "adj_val=adj_val[0:10*N_shot*4+10*N_shot,Random_idx_val]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rXMvNIZF6BU"
      },
      "source": [
        "# Constructing hidden_labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL4nZ9-pMmSM"
      },
      "source": [
        "#hidden_labels:\n",
        "#برای استفاده در قسمت اکتیولرنینگ که فقط بر روی هیدن لیبل ها اعمال شود\n",
        "#سایز آن به اندازه تعداد کل سمپل ها می باشد\n",
        "hidden_labels_train=np.zeros((10*N_shot*4+10*N_shot), dtype='int')\n",
        "hidden_labels_train[10*N_shot:10*N_shot*4+10*N_shot]=1\n",
        "#RuntimeError: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead. site:stackoverflow.com\n",
        "#برای همین به تنسور تبدیلش کردم\n",
        "hidden_labels_train=torch.tensor(hidden_labels_train)\n",
        "#hidden_labels_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSwwuzUJFR1n"
      },
      "source": [
        "hidden_labels_test=np.zeros((10*N_shot*4+10*N_shot), dtype='int')\n",
        "hidden_labels_test[10*N_shot:10*N_shot*4+10*N_shot]=1\n",
        "hidden_labels_test=torch.tensor(hidden_labels_test)\n",
        "#hidden_labels_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46SwJE2eFRj4"
      },
      "source": [
        "hidden_labels_val=np.zeros((10*N_shot*4+10*N_shot), dtype='int')\n",
        "hidden_labels_val[10*N_shot:10*N_shot*4+10*N_shot]=1\n",
        "hidden_labels_val=torch.tensor(hidden_labels_val)\n",
        "#hidden_labels_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNJQMW6-a2-h",
        "outputId": "29322972-3dd6-4565-9bd2-48f4c259825d"
      },
      "source": [
        "features.shape[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13752"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRzfVoOLakwY"
      },
      "source": [
        "hidden_labels=np.zeros((features.shape[0]), dtype='int')\n",
        "hidden_labels=torch.tensor(hidden_labels)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7zL2lQQRV9V",
        "outputId": "76792705-9ea5-44bf-97f5-7c6ff08862ac"
      },
      "source": [
        "hidden_labels_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScJWIK7yGDcY"
      },
      "source": [
        "#Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us3XSHLHDWoP"
      },
      "source": [
        "\n",
        "import math\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "#class parameter:\n",
        "#پارامترها را کش می کند\n",
        "\n",
        "from torch.nn.modules.module import Module\n",
        "\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features ,out_features, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        \n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        if self.bias is not None:\n",
        "            self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "    def forward(self, input, input_adj):\n",
        "        support = torch.mm(input, self.weight)\n",
        "        #torch.mm=matrix multiplication\n",
        "        #torch.spmm=Sparse matrix multiplication\n",
        "        #ضرب ویژگی ها در ماتریس مجاورت\n",
        "        output = torch.spmm(input_adj, support)\n",
        "        if self.bias is not None:\n",
        "            return output + self.bias\n",
        "        else:\n",
        "            return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vTcR4OmGJIR"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXDaJHg7DeHl"
      },
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid,nclass, dropout):\n",
        "        super(GCN, self).__init__()\n",
        "\n",
        "        self.gc1 = GraphConvolution(nfeat, nhid)\n",
        "        self.gc2 = GraphConvolution(nhid, nclass)\n",
        "        self.dropout = dropout\n",
        "       \n",
        "        \n",
        "    def forward(self, x, input_adj,hidden_labels,mode):\n",
        "        #if N-shot=10 then samples=500\n",
        "        #features_num=767\n",
        "        #x.shape=500*767\n",
        "        #samples=500,features=767\n",
        "        x = F.relu(self.gc1(x, input_adj))\n",
        "        #x.shape=500*16\n",
        "        #hidden_unit=16\n",
        "        if mode==0:\n",
        "          x = F.dropout(x, self.dropout)\n",
        "        #training=self.training parameter of drop out func\n",
        "        #x.shape=500*16\n",
        "        #hidden_unit=16\n",
        "        #طبق مقاله مربوط به اکتیولرنینگ بعد از لایه اول اکتیو لرنینگ را اجرا می کنیم تا تصمیم گیری شود که لیبل کدام یک از داده های هیدن را اضافه کنیم\n",
        "        if mode !=-1:\n",
        "          x,decision=self.active(x,hidden_labels)\n",
        "        else:\n",
        "          decision=-1  \n",
        "        x = self.gc2(x, input_adj)\n",
        "        #x.shape=500*11\n",
        "        #class_num=11\n",
        "        return F.log_softmax(x,dim=1),x,decision\n",
        "\n",
        "    def active(self, x,hidden):\n",
        "        #x.shape=500*16\n",
        "        x_active = torch.transpose(x, 0, 1) \n",
        "        x_active=x_active.unsqueeze_(0)\n",
        "        #unsqueeze_داده 2 بعدی را به 3 بعدی تبدیل می کند و بعد اول را 1 می کند\n",
        "        #این کار را برای آنکه لایه کانولوشن درست کار کند انجام دادم\n",
        "        #x_active.shape=1*16*500\n",
        "        #x_active.shape[1]=16\n",
        "\n",
        "        conv_active_1 = nn.Conv1d(x_active.shape[1],x_active.shape[1],1)\n",
        "        bn_active = nn.BatchNorm1d(x_active.shape[1])\n",
        "        conv_active_2 = nn.Conv1d(x_active.shape[1],1,1)\n",
        "\n",
        "        x_active = conv_active_1(x_active)\n",
        "        #x_active.shape=1*16*500\n",
        "        x_active = F.leaky_relu(bn_active(x_active))\n",
        "        #x_active.shape=1*16*500\n",
        "        x_active = conv_active_2(x_active)\n",
        "        #x_active.shape=1*1*500 \n",
        "        x_active = torch.transpose(x_active, 0, 1) \n",
        "        x_active = x_active.squeeze(0) \n",
        "        #x_active.shape=1*500 \n",
        "        #squeeze_ داده 3 بعدی را به 2 بعدی تبدیل می کند و مجدداورودی به حالت اول بر می گردد\n",
        "\n",
        "        #x_active = x_active - (1-hidden)*1e8\n",
        "        x_active = F.softmax(x_active)\n",
        "        #x_active.shape=1*500 \n",
        "        \n",
        "        #برای آنکه فقط روی هیدن لیبل ها تصمیم گیری شود، با ضرب زیر مقدار مربوط به سمپل های با لیبل صفر می شود\n",
        "        x_active = x_active*hidden \n",
        "        decision = torch.argmax(x_active)\n",
        "        decision = decision.detach()\n",
        "        return x,int(decision)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYdsEgftGRS8"
      },
      "source": [
        "#Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kAvN1C2QDq89",
        "outputId": "fd3199e9-65af-4a2e-af6f-43e0be6069a3"
      },
      "source": [
        "\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import time\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "# Training settings\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--no-cuda', action='store_true', default=False,\n",
        "                    help='Disables CUDA training.')\n",
        "parser.add_argument('--fastmode', action='store_true', default=False,\n",
        "                    help='Validate during training pass.')\n",
        "parser.add_argument('--seed', type=int, default=42, help='Random seed.')\n",
        "parser.add_argument('--epochs', type=int, default=800,\n",
        "                    help='Number of epochs to train.')\n",
        "parser.add_argument('--lr', type=float, default=0.01,\n",
        "                    help='Initial learning rate.')\n",
        "parser.add_argument('--weight_decay', type=float, default=5e-4,\n",
        "                    help='Weight decay (L2 loss on parameters).')\n",
        "parser.add_argument('--hidden', type=int, default=16,\n",
        "                    help='Number of hidden units.')\n",
        "parser.add_argument('--dropout', type=float, default=0.5,\n",
        "                    help='Dropout rate (1 - keep probability).')\n",
        "\n",
        "\n",
        "#args = parser.parse_args()\n",
        "#error midad khate bala,khate paein jaigozin shod\n",
        "\n",
        "args = parser.parse_known_args()[0]\n",
        "\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "np.random.seed(args.seed)\n",
        "torch.manual_seed(args.seed)\n",
        "if args.cuda:\n",
        "    torch.cuda.manual_seed(args.seed)\n",
        "\n",
        "\n",
        "# Model and optimizer\n",
        "model = GCN(nfeat=features.shape[1],\n",
        "            nhid=args.hidden,\n",
        "            nclass=class_names.size+1,\n",
        "            #بدلیل صفر کردن لیبل هیدن ها تعداد کلاسها یکی بیشتر میشود\n",
        "            dropout=args.dropout\n",
        "            )\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(),\n",
        "                       lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "# to set cuda as your device if possible\n",
        "#training on  GPU\n",
        "\n",
        "if args.cuda:\n",
        "    model.cuda()\n",
        "    features_test = features_test.cuda()\n",
        "    adj_test = adj_test.cuda()\n",
        "    labels_test = labels_test.cuda()\n",
        "    features_train = features_train.cuda()\n",
        "    adj_train = adj_train.cuda()\n",
        "    labels_train = labels_train.cuda()\n",
        "    features_val = features_val.cuda()\n",
        "    adj_val = adj_val.cuda()\n",
        "    labels_val = labels_val.cuda()\n",
        "    # train:adjust the weights on the neural network\n",
        "    # validation:used to minimize overfitting\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  optimizer.zero_grad()\n",
        "  output,predicted_output,act_dec = model(features_train,adj_train,hidden_labels_train,mode=0)\n",
        "\n",
        "  #مقدار تصمیم گیری شده در اکتیولرنینگ یک اندیس از هیدن لیبل هاست که بیشترین تاثیر در بهبود خطاهای شبکه را دارد\n",
        "  #(در واقع مقدارش را صفر میکنیم)لیبل آن را بدست آورده و به لیبل ها اضافه می کنیمو از هیدن ها هم آن را حذف میکنیم\n",
        "\n",
        "  Uncover_label=labels_train_hidden[act_dec]\n",
        "  labels_train[act_dec]=Uncover_label\n",
        "  hidden_labels_train[act_dec]=0\n",
        "\n",
        "  loss_train = F.nll_loss(output, labels_train)\n",
        "  acc_train = accuracy(output,labels_train)\n",
        "  # Computing the gradients necessary to adjust the weights\n",
        "  loss_train.backward()\n",
        "  # Updating the weights of the neural network\n",
        "  optimizer.step()\n",
        "  losses.append(loss_train.item())\n",
        "  acc.append(acc_train.item())\n",
        "\n",
        "  if not args.fastmode:\n",
        "    # Evaluate validation set performance separately,\n",
        "    # deactivates dropout during validation run.\n",
        "    model.eval()\n",
        "    output,predicted_output,act_dec_val = model(features_val, adj_val,hidden_labels_val,mode=1)\n",
        "    \n",
        "  Uncover_label=labels_val_hidden[act_dec_val]\n",
        "  labels_val[act_dec_val]=Uncover_label\n",
        "  hidden_labels_val[act_dec_val]=0\n",
        "  \n",
        "  loss_val = F.nll_loss(output, labels_val)\n",
        "  acc_val = accuracy(output, labels_val)\n",
        "  losses_val.append(loss_val.item())\n",
        "  acc_valid.append(acc_val.item())\n",
        "\n",
        "  print('Epoch: {:04d}'.format(epoch+1),\n",
        "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
        "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
        "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
        "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
        "          'time: {:.4f}s'.format(time.time() - t),\n",
        "          act_dec,act_dec_val)\n",
        "\n",
        "# Train model\n",
        "t_total = time.time()\n",
        "losses = []\n",
        "acc=[]\n",
        "losses_val = []\n",
        "acc_valid=[]\n",
        "t = time.time()\n",
        "for epoch in range(args.epochs):\n",
        "    train(epoch)\n",
        "\n",
        "\n",
        "def test(): \n",
        "    model.eval()\n",
        "  \n",
        "    output,predicted_output,act_dec = model(features[idx_test]\n",
        "                   ,adj[idx_test[0]:int(idx_test[-1])+1,idx_test[0]:int(idx_test[-1])+1],hidden_labels[idx_test],mode=-1)\n",
        "    \n",
        "    #Uncover_label=labels_test_hidden[act_dec]\n",
        "    #labels_test[act_dec]=Uncover_label\n",
        "    #hidden_labels_test[act_dec]=0\n",
        "\n",
        "    loss_test = F.nll_loss(output, labels[idx_test])\n",
        "    acc_test = accuracy(output, labels[idx_test])\n",
        "    print(\"Test set results:\",\n",
        "          \"loss= {:.4f}\".format(loss_test.item()),\n",
        "          \"accuracy= {:.4f}\".format(acc_test.item()),\n",
        "          \"act_dec_test= {:.4f}\".format(act_dec))\n",
        "# Testing\n",
        "test()\n",
        "\n",
        "print(model)\n",
        "\n",
        "#plotting loss_train_val:\n",
        "\n",
        "plt.plot(np.array(losses),label ='loss_train Plot')\n",
        "plt.plot(np.array(losses_val),label ='loss_val Plot')\n",
        "plt.title('loss_train_validation Plot')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('value')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "#plotting acc_train_val:\n",
        "\n",
        "plt.plot(np.array(acc),label ='Accuracy_train Plot')\n",
        "plt.plot(np.array(acc_valid),label ='Accuracy_val Plot')\n",
        "plt.title('acc_train_validation Plot')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('value')\n",
        "plt.legend()\n",
        "plt.show()    \n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "print(\"Total time elapsed: {:.4f}s\".format(time.time() - t_total))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 2.3393 acc_train: 0.0260 loss_val: 2.4050 acc_val: 0.1060 time: 0.0159s 198 321\n",
            "Epoch: 0002 loss_train: 2.3060 acc_train: 0.0700 loss_val: 2.4514 acc_val: 0.3440 time: 0.0288s 447 389\n",
            "Epoch: 0003 loss_train: 2.2881 acc_train: 0.2960 loss_val: 2.4836 acc_val: 0.7720 time: 0.0429s 491 109\n",
            "Epoch: 0004 loss_train: 2.2320 acc_train: 0.7300 loss_val: 2.5287 acc_val: 0.7920 time: 0.0558s 443 282\n",
            "Epoch: 0005 loss_train: 2.2315 acc_train: 0.7640 loss_val: 2.5841 acc_val: 0.7900 time: 0.0715s 166 253\n",
            "Epoch: 0006 loss_train: 2.1829 acc_train: 0.7820 loss_val: 2.6652 acc_val: 0.7880 time: 0.0844s 125 486\n",
            "Epoch: 0007 loss_train: 2.2266 acc_train: 0.7820 loss_val: 2.7343 acc_val: 0.7860 time: 0.0988s 403 251\n",
            "Epoch: 0008 loss_train: 2.1877 acc_train: 0.7840 loss_val: 2.7896 acc_val: 0.7840 time: 0.1142s 183 319\n",
            "Epoch: 0009 loss_train: 2.1354 acc_train: 0.7840 loss_val: 2.8446 acc_val: 0.7820 time: 0.1276s 482 262\n",
            "Epoch: 0010 loss_train: 2.1316 acc_train: 0.7800 loss_val: 2.8879 acc_val: 0.7800 time: 0.1410s 195 497\n",
            "Epoch: 0011 loss_train: 2.0932 acc_train: 0.7800 loss_val: 2.9260 acc_val: 0.7780 time: 0.1544s 244 359\n",
            "Epoch: 0012 loss_train: 2.0917 acc_train: 0.7780 loss_val: 2.9666 acc_val: 0.7760 time: 0.1687s 405 215\n",
            "Epoch: 0013 loss_train: 2.0534 acc_train: 0.7760 loss_val: 3.0177 acc_val: 0.7740 time: 0.1877s 414 182\n",
            "Epoch: 0014 loss_train: 2.0473 acc_train: 0.7720 loss_val: 3.0606 acc_val: 0.7720 time: 0.2030s 204 173\n",
            "Epoch: 0015 loss_train: 2.0309 acc_train: 0.7720 loss_val: 3.1017 acc_val: 0.7700 time: 0.2220s 220 311\n",
            "Epoch: 0016 loss_train: 2.0116 acc_train: 0.7700 loss_val: 3.1463 acc_val: 0.7680 time: 0.2355s 455 180\n",
            "Epoch: 0017 loss_train: 2.0301 acc_train: 0.7660 loss_val: 3.1780 acc_val: 0.7660 time: 0.2492s 291 240\n",
            "Epoch: 0018 loss_train: 1.9936 acc_train: 0.7640 loss_val: 3.2065 acc_val: 0.7640 time: 0.2633s 351 462\n",
            "Epoch: 0019 loss_train: 1.9882 acc_train: 0.7620 loss_val: 3.2514 acc_val: 0.7620 time: 0.2776s 477 290\n",
            "Epoch: 0020 loss_train: 1.9625 acc_train: 0.7620 loss_val: 3.2949 acc_val: 0.7600 time: 0.2884s 315 176\n",
            "Epoch: 0021 loss_train: 1.9522 acc_train: 0.7660 loss_val: 3.3226 acc_val: 0.7580 time: 0.3014s 163 164\n",
            "Epoch: 0022 loss_train: 1.8931 acc_train: 0.7600 loss_val: 3.3705 acc_val: 0.7560 time: 0.3161s 231 278\n",
            "Epoch: 0023 loss_train: 1.8983 acc_train: 0.7580 loss_val: 3.4353 acc_val: 0.7540 time: 0.3323s 396 104\n",
            "Epoch: 0024 loss_train: 1.9088 acc_train: 0.7520 loss_val: 3.4587 acc_val: 0.7520 time: 0.3509s 104 199\n",
            "Epoch: 0025 loss_train: 1.8872 acc_train: 0.7540 loss_val: 3.4783 acc_val: 0.7500 time: 0.3659s 140 476\n",
            "Epoch: 0026 loss_train: 1.8687 acc_train: 0.7500 loss_val: 3.4767 acc_val: 0.7480 time: 0.3800s 489 445\n",
            "Epoch: 0027 loss_train: 1.8374 acc_train: 0.7500 loss_val: 3.4607 acc_val: 0.7460 time: 0.3939s 137 134\n",
            "Epoch: 0028 loss_train: 1.8503 acc_train: 0.7480 loss_val: 3.4354 acc_val: 0.7440 time: 0.4095s 350 385\n",
            "Epoch: 0029 loss_train: 1.8378 acc_train: 0.7500 loss_val: 3.3979 acc_val: 0.7420 time: 0.4299s 180 443\n",
            "Epoch: 0030 loss_train: 1.7968 acc_train: 0.7500 loss_val: 3.3747 acc_val: 0.7400 time: 0.4448s 147 237\n",
            "Epoch: 0031 loss_train: 1.8119 acc_train: 0.7500 loss_val: 3.3426 acc_val: 0.7380 time: 0.4597s 435 236\n",
            "Epoch: 0032 loss_train: 1.7748 acc_train: 0.7500 loss_val: 3.3287 acc_val: 0.7360 time: 0.4731s 398 460\n",
            "Epoch: 0033 loss_train: 1.7802 acc_train: 0.7500 loss_val: 3.3176 acc_val: 0.7340 time: 0.4869s 225 130\n",
            "Epoch: 0034 loss_train: 1.7965 acc_train: 0.7480 loss_val: 3.3039 acc_val: 0.7320 time: 0.5011s 424 475\n",
            "Epoch: 0035 loss_train: 1.7575 acc_train: 0.7460 loss_val: 3.2959 acc_val: 0.7300 time: 0.5143s 340 305\n",
            "Epoch: 0036 loss_train: 1.8188 acc_train: 0.7420 loss_val: 3.2433 acc_val: 0.7280 time: 0.5324s 172 482\n",
            "Epoch: 0037 loss_train: 1.7924 acc_train: 0.7480 loss_val: 3.1778 acc_val: 0.7260 time: 0.5468s 144 247\n",
            "Epoch: 0038 loss_train: 1.7857 acc_train: 0.7440 loss_val: 3.0730 acc_val: 0.7240 time: 0.5603s 164 289\n",
            "Epoch: 0039 loss_train: 1.7588 acc_train: 0.7420 loss_val: 2.9422 acc_val: 0.7220 time: 0.5732s 352 121\n",
            "Epoch: 0040 loss_train: 1.7385 acc_train: 0.7460 loss_val: 2.8105 acc_val: 0.7200 time: 0.5867s 257 225\n",
            "Epoch: 0041 loss_train: 1.7248 acc_train: 0.7420 loss_val: 2.6871 acc_val: 0.7200 time: 0.5995s 496 160\n",
            "Epoch: 0042 loss_train: 1.7129 acc_train: 0.7420 loss_val: 2.5895 acc_val: 0.7180 time: 0.6147s 346 474\n",
            "Epoch: 0043 loss_train: 1.7129 acc_train: 0.7340 loss_val: 2.5043 acc_val: 0.7160 time: 0.6382s 130 216\n",
            "Epoch: 0044 loss_train: 1.6847 acc_train: 0.7360 loss_val: 2.4638 acc_val: 0.7140 time: 0.6669s 176 312\n",
            "Epoch: 0045 loss_train: 1.6702 acc_train: 0.7380 loss_val: 2.4397 acc_val: 0.7120 time: 0.6819s 277 334\n",
            "Epoch: 0046 loss_train: 1.6560 acc_train: 0.7360 loss_val: 2.4407 acc_val: 0.7100 time: 0.6982s 228 440\n",
            "Epoch: 0047 loss_train: 1.6529 acc_train: 0.7300 loss_val: 2.4516 acc_val: 0.7080 time: 0.7128s 372 428\n",
            "Epoch: 0048 loss_train: 1.6481 acc_train: 0.7220 loss_val: 2.4455 acc_val: 0.7060 time: 0.7252s 493 438\n",
            "Epoch: 0049 loss_train: 1.6228 acc_train: 0.7260 loss_val: 2.4314 acc_val: 0.7020 time: 0.7386s 349 449\n",
            "Epoch: 0050 loss_train: 1.6225 acc_train: 0.7220 loss_val: 2.3808 acc_val: 0.7020 time: 0.7543s 111 163\n",
            "Epoch: 0051 loss_train: 1.6219 acc_train: 0.7240 loss_val: 2.3264 acc_val: 0.7000 time: 0.7670s 439 347\n",
            "Epoch: 0052 loss_train: 1.6177 acc_train: 0.7120 loss_val: 2.3025 acc_val: 0.6980 time: 0.7834s 423 161\n",
            "Epoch: 0053 loss_train: 1.6135 acc_train: 0.7280 loss_val: 2.2482 acc_val: 0.6960 time: 0.7968s 450 281\n",
            "Epoch: 0054 loss_train: 1.5935 acc_train: 0.7140 loss_val: 2.2535 acc_val: 0.6940 time: 0.8108s 135 335\n",
            "Epoch: 0055 loss_train: 1.5914 acc_train: 0.7160 loss_val: 2.2662 acc_val: 0.6900 time: 0.8245s 418 308\n",
            "Epoch: 0056 loss_train: 1.6154 acc_train: 0.7120 loss_val: 2.2822 acc_val: 0.6880 time: 0.8392s 102 403\n",
            "Epoch: 0057 loss_train: 1.5936 acc_train: 0.7100 loss_val: 2.3048 acc_val: 0.6860 time: 0.8579s 223 380\n",
            "Epoch: 0058 loss_train: 1.5676 acc_train: 0.7180 loss_val: 2.3414 acc_val: 0.6860 time: 0.8717s 103 354\n",
            "Epoch: 0059 loss_train: 1.5473 acc_train: 0.7160 loss_val: 2.3866 acc_val: 0.6840 time: 0.8848s 367 400\n",
            "Epoch: 0060 loss_train: 1.5364 acc_train: 0.7080 loss_val: 2.4410 acc_val: 0.6820 time: 0.8999s 222 227\n",
            "Epoch: 0061 loss_train: 1.5500 acc_train: 0.7140 loss_val: 2.4436 acc_val: 0.6800 time: 0.9136s 279 421\n",
            "Epoch: 0062 loss_train: 1.5166 acc_train: 0.7100 loss_val: 2.4583 acc_val: 0.6780 time: 0.9572s 384 488\n",
            "Epoch: 0063 loss_train: 1.5056 acc_train: 0.7100 loss_val: 2.4876 acc_val: 0.6760 time: 0.9776s 109 297\n",
            "Epoch: 0064 loss_train: 1.5018 acc_train: 0.7060 loss_val: 2.5155 acc_val: 0.6760 time: 0.9925s 245 465\n",
            "Epoch: 0065 loss_train: 1.5152 acc_train: 0.7020 loss_val: 2.5274 acc_val: 0.6740 time: 1.0060s 490 280\n",
            "Epoch: 0066 loss_train: 1.5095 acc_train: 0.7020 loss_val: 2.5056 acc_val: 0.6740 time: 1.0200s 457 201\n",
            "Epoch: 0067 loss_train: 1.4929 acc_train: 0.7060 loss_val: 2.4826 acc_val: 0.6720 time: 1.0354s 233 499\n",
            "Epoch: 0068 loss_train: 1.5297 acc_train: 0.7020 loss_val: 2.4461 acc_val: 0.6680 time: 1.0496s 248 328\n",
            "Epoch: 0069 loss_train: 1.5080 acc_train: 0.6980 loss_val: 2.4126 acc_val: 0.6680 time: 1.0680s 416 166\n",
            "Epoch: 0070 loss_train: 1.4859 acc_train: 0.7000 loss_val: 2.3972 acc_val: 0.6660 time: 1.0814s 324 352\n",
            "Epoch: 0071 loss_train: 1.5042 acc_train: 0.6960 loss_val: 2.3481 acc_val: 0.6640 time: 1.0942s 120 285\n",
            "Epoch: 0072 loss_train: 1.4806 acc_train: 0.6960 loss_val: 2.2861 acc_val: 0.6640 time: 1.1070s 213 229\n",
            "Epoch: 0073 loss_train: 1.4783 acc_train: 0.6900 loss_val: 2.2529 acc_val: 0.6660 time: 1.1202s 191 220\n",
            "Epoch: 0074 loss_train: 1.4766 acc_train: 0.6980 loss_val: 2.1878 acc_val: 0.6640 time: 1.1353s 234 147\n",
            "Epoch: 0075 loss_train: 1.4752 acc_train: 0.6820 loss_val: 2.1401 acc_val: 0.6620 time: 1.1492s 210 152\n",
            "Epoch: 0076 loss_train: 1.4550 acc_train: 0.6880 loss_val: 2.0968 acc_val: 0.6620 time: 1.1634s 438 211\n",
            "Epoch: 0077 loss_train: 1.4559 acc_train: 0.6940 loss_val: 2.0742 acc_val: 0.6620 time: 1.1788s 127 273\n",
            "Epoch: 0078 loss_train: 1.4829 acc_train: 0.6900 loss_val: 2.0729 acc_val: 0.6600 time: 1.1920s 269 178\n",
            "Epoch: 0079 loss_train: 1.4580 acc_train: 0.6960 loss_val: 2.0748 acc_val: 0.6620 time: 1.2061s 264 456\n",
            "Epoch: 0080 loss_train: 1.4580 acc_train: 0.6920 loss_val: 2.0709 acc_val: 0.6600 time: 1.2180s 250 495\n",
            "Epoch: 0081 loss_train: 1.4552 acc_train: 0.6780 loss_val: 2.0640 acc_val: 0.6580 time: 1.2307s 388 405\n",
            "Epoch: 0082 loss_train: 1.4641 acc_train: 0.6860 loss_val: 2.0740 acc_val: 0.6540 time: 1.2422s 458 265\n",
            "Epoch: 0083 loss_train: 1.4486 acc_train: 0.6800 loss_val: 2.0994 acc_val: 0.6520 time: 1.2577s 358 448\n",
            "Epoch: 0084 loss_train: 1.4620 acc_train: 0.6700 loss_val: 2.1099 acc_val: 0.6500 time: 1.2755s 442 252\n",
            "Epoch: 0085 loss_train: 1.4277 acc_train: 0.6720 loss_val: 2.1280 acc_val: 0.6480 time: 1.2897s 184 207\n",
            "Epoch: 0086 loss_train: 1.4577 acc_train: 0.6720 loss_val: 2.1349 acc_val: 0.6480 time: 1.3009s 492 256\n",
            "Epoch: 0087 loss_train: 1.4325 acc_train: 0.6740 loss_val: 2.1441 acc_val: 0.6460 time: 1.3129s 202 487\n",
            "Epoch: 0088 loss_train: 1.4178 acc_train: 0.6740 loss_val: 2.1473 acc_val: 0.6440 time: 1.3262s 182 254\n",
            "Epoch: 0089 loss_train: 1.4138 acc_train: 0.6760 loss_val: 2.1480 acc_val: 0.6420 time: 1.3399s 229 444\n",
            "Epoch: 0090 loss_train: 1.4448 acc_train: 0.6600 loss_val: 2.1408 acc_val: 0.6420 time: 1.3527s 499 115\n",
            "Epoch: 0091 loss_train: 1.4298 acc_train: 0.6600 loss_val: 2.1181 acc_val: 0.6400 time: 1.3661s 188 145\n",
            "Epoch: 0092 loss_train: 1.4306 acc_train: 0.6740 loss_val: 2.0890 acc_val: 0.6380 time: 1.3784s 426 194\n",
            "Epoch: 0093 loss_train: 1.4074 acc_train: 0.6680 loss_val: 2.0769 acc_val: 0.6320 time: 1.3919s 337 260\n",
            "Epoch: 0094 loss_train: 1.4037 acc_train: 0.6600 loss_val: 2.0660 acc_val: 0.6300 time: 1.4064s 444 365\n",
            "Epoch: 0095 loss_train: 1.4220 acc_train: 0.6720 loss_val: 2.0617 acc_val: 0.6300 time: 1.4185s 215 217\n",
            "Epoch: 0096 loss_train: 1.4010 acc_train: 0.6680 loss_val: 2.0657 acc_val: 0.6280 time: 1.4334s 432 473\n",
            "Epoch: 0097 loss_train: 1.4074 acc_train: 0.6600 loss_val: 2.0618 acc_val: 0.6260 time: 1.4487s 235 369\n",
            "Epoch: 0098 loss_train: 1.4399 acc_train: 0.6520 loss_val: 2.0415 acc_val: 0.6240 time: 1.4626s 285 167\n",
            "Epoch: 0099 loss_train: 1.3812 acc_train: 0.6680 loss_val: 2.0250 acc_val: 0.6220 time: 1.4761s 425 159\n",
            "Epoch: 0100 loss_train: 1.4058 acc_train: 0.6660 loss_val: 2.0212 acc_val: 0.6220 time: 1.4924s 117 119\n",
            "Epoch: 0101 loss_train: 1.4169 acc_train: 0.6560 loss_val: 2.0196 acc_val: 0.6200 time: 1.5076s 313 284\n",
            "Epoch: 0102 loss_train: 1.4041 acc_train: 0.6460 loss_val: 2.0267 acc_val: 0.6180 time: 1.5208s 325 179\n",
            "Epoch: 0103 loss_train: 1.4176 acc_train: 0.6480 loss_val: 2.0366 acc_val: 0.6160 time: 1.5378s 107 206\n",
            "Epoch: 0104 loss_train: 1.4100 acc_train: 0.6520 loss_val: 2.0388 acc_val: 0.6140 time: 1.5531s 328 243\n",
            "Epoch: 0105 loss_train: 1.4258 acc_train: 0.6480 loss_val: 2.0275 acc_val: 0.6160 time: 1.5696s 276 357\n",
            "Epoch: 0106 loss_train: 1.4110 acc_train: 0.6500 loss_val: 2.0141 acc_val: 0.6180 time: 1.5858s 119 393\n",
            "Epoch: 0107 loss_train: 1.4001 acc_train: 0.6520 loss_val: 2.0255 acc_val: 0.6160 time: 1.5985s 243 433\n",
            "Epoch: 0108 loss_train: 1.3759 acc_train: 0.6680 loss_val: 2.0467 acc_val: 0.6120 time: 1.6121s 415 200\n",
            "Epoch: 0109 loss_train: 1.3918 acc_train: 0.6560 loss_val: 2.0532 acc_val: 0.6100 time: 1.6249s 481 208\n",
            "Epoch: 0110 loss_train: 1.4134 acc_train: 0.6400 loss_val: 2.0521 acc_val: 0.6100 time: 1.6379s 406 185\n",
            "Epoch: 0111 loss_train: 1.4189 acc_train: 0.6480 loss_val: 2.0477 acc_val: 0.6080 time: 1.6508s 354 348\n",
            "Epoch: 0112 loss_train: 1.4021 acc_train: 0.6480 loss_val: 2.0719 acc_val: 0.6060 time: 1.6647s 226 158\n",
            "Epoch: 0113 loss_train: 1.3997 acc_train: 0.6460 loss_val: 2.0938 acc_val: 0.6060 time: 1.6780s 385 118\n",
            "Epoch: 0114 loss_train: 1.3959 acc_train: 0.6420 loss_val: 2.0926 acc_val: 0.6040 time: 1.6916s 136 157\n",
            "Epoch: 0115 loss_train: 1.3755 acc_train: 0.6500 loss_val: 2.0657 acc_val: 0.6020 time: 1.7103s 259 401\n",
            "Epoch: 0116 loss_train: 1.4188 acc_train: 0.6380 loss_val: 2.0544 acc_val: 0.6000 time: 1.7237s 480 424\n",
            "Epoch: 0117 loss_train: 1.4236 acc_train: 0.6260 loss_val: 2.0397 acc_val: 0.5940 time: 1.7407s 373 266\n",
            "Epoch: 0118 loss_train: 1.3894 acc_train: 0.6480 loss_val: 2.0195 acc_val: 0.5900 time: 1.7536s 345 455\n",
            "Epoch: 0119 loss_train: 1.3733 acc_train: 0.6500 loss_val: 2.0158 acc_val: 0.5900 time: 1.7679s 232 197\n",
            "Epoch: 0120 loss_train: 1.3914 acc_train: 0.6360 loss_val: 2.0027 acc_val: 0.5900 time: 1.7812s 278 244\n",
            "Epoch: 0121 loss_train: 1.3848 acc_train: 0.6360 loss_val: 2.0050 acc_val: 0.5900 time: 1.7946s 428 395\n",
            "Epoch: 0122 loss_train: 1.4032 acc_train: 0.6280 loss_val: 2.0239 acc_val: 0.5880 time: 1.8069s 495 226\n",
            "Epoch: 0123 loss_train: 1.3927 acc_train: 0.6260 loss_val: 2.0415 acc_val: 0.5860 time: 1.8201s 143 316\n",
            "Epoch: 0124 loss_train: 1.4020 acc_train: 0.6200 loss_val: 2.0722 acc_val: 0.5860 time: 1.8336s 348 172\n",
            "Epoch: 0125 loss_train: 1.3872 acc_train: 0.6400 loss_val: 2.1115 acc_val: 0.5840 time: 1.8479s 214 481\n",
            "Epoch: 0126 loss_train: 1.3519 acc_train: 0.6480 loss_val: 2.1568 acc_val: 0.5820 time: 1.8644s 461 341\n",
            "Epoch: 0127 loss_train: 1.3910 acc_train: 0.6360 loss_val: 2.1834 acc_val: 0.5800 time: 1.8776s 471 246\n",
            "Epoch: 0128 loss_train: 1.3739 acc_train: 0.6340 loss_val: 2.1955 acc_val: 0.5780 time: 1.8902s 251 195\n",
            "Epoch: 0129 loss_train: 1.3773 acc_train: 0.6240 loss_val: 2.1820 acc_val: 0.5760 time: 1.9030s 382 264\n",
            "Epoch: 0130 loss_train: 1.3761 acc_train: 0.6340 loss_val: 2.1608 acc_val: 0.5740 time: 1.9183s 192 361\n",
            "Epoch: 0131 loss_train: 1.3942 acc_train: 0.6260 loss_val: 2.1109 acc_val: 0.5720 time: 1.9367s 148 363\n",
            "Epoch: 0132 loss_train: 1.3897 acc_train: 0.6300 loss_val: 2.0474 acc_val: 0.5680 time: 1.9504s 167 384\n",
            "Epoch: 0133 loss_train: 1.3705 acc_train: 0.6380 loss_val: 2.0225 acc_val: 0.5680 time: 1.9648s 299 125\n",
            "Epoch: 0134 loss_train: 1.3784 acc_train: 0.6260 loss_val: 2.0137 acc_val: 0.5700 time: 1.9820s 121 293\n",
            "Epoch: 0135 loss_train: 1.3585 acc_train: 0.6280 loss_val: 2.0227 acc_val: 0.5700 time: 1.9959s 249 470\n",
            "Epoch: 0136 loss_train: 1.3948 acc_train: 0.6300 loss_val: 2.0524 acc_val: 0.5660 time: 2.0077s 454 368\n",
            "Epoch: 0137 loss_train: 1.3745 acc_train: 0.6400 loss_val: 2.0918 acc_val: 0.5640 time: 2.0193s 362 430\n",
            "Epoch: 0138 loss_train: 1.3633 acc_train: 0.6360 loss_val: 2.1811 acc_val: 0.5620 time: 2.0312s 116 204\n",
            "Epoch: 0139 loss_train: 1.3938 acc_train: 0.6260 loss_val: 2.2750 acc_val: 0.5580 time: 2.0429s 459 490\n",
            "Epoch: 0140 loss_train: 1.3724 acc_train: 0.6420 loss_val: 2.3028 acc_val: 0.5580 time: 2.0566s 339 106\n",
            "Epoch: 0141 loss_train: 1.3765 acc_train: 0.6180 loss_val: 2.3254 acc_val: 0.5560 time: 2.0693s 449 463\n",
            "Epoch: 0142 loss_train: 1.3505 acc_train: 0.6500 loss_val: 2.3352 acc_val: 0.5540 time: 2.0823s 151 231\n",
            "Epoch: 0143 loss_train: 1.3908 acc_train: 0.6200 loss_val: 2.3241 acc_val: 0.5540 time: 2.0945s 465 238\n",
            "Epoch: 0144 loss_train: 1.3740 acc_train: 0.6300 loss_val: 2.2933 acc_val: 0.5520 time: 2.1072s 197 331\n",
            "Epoch: 0145 loss_train: 1.3602 acc_train: 0.6400 loss_val: 2.2655 acc_val: 0.5500 time: 2.1190s 370 397\n",
            "Epoch: 0146 loss_train: 1.3800 acc_train: 0.6300 loss_val: 2.2365 acc_val: 0.5480 time: 2.1347s 359 353\n",
            "Epoch: 0147 loss_train: 1.3559 acc_train: 0.6240 loss_val: 2.2101 acc_val: 0.5480 time: 2.1510s 227 298\n",
            "Epoch: 0148 loss_train: 1.3713 acc_train: 0.6280 loss_val: 2.1894 acc_val: 0.5500 time: 2.1640s 174 344\n",
            "Epoch: 0149 loss_train: 1.3726 acc_train: 0.6320 loss_val: 2.1906 acc_val: 0.5500 time: 2.1766s 402 146\n",
            "Epoch: 0150 loss_train: 1.3834 acc_train: 0.6160 loss_val: 2.1789 acc_val: 0.5480 time: 2.1888s 456 469\n",
            "Epoch: 0151 loss_train: 1.3742 acc_train: 0.6260 loss_val: 2.1728 acc_val: 0.5500 time: 2.2010s 100 126\n",
            "Epoch: 0152 loss_train: 1.3892 acc_train: 0.6200 loss_val: 2.1689 acc_val: 0.5520 time: 2.2135s 212 140\n",
            "Epoch: 0153 loss_train: 1.3778 acc_train: 0.6160 loss_val: 2.1736 acc_val: 0.5500 time: 2.2307s 283 313\n",
            "Epoch: 0154 loss_train: 1.3615 acc_train: 0.6340 loss_val: 2.1712 acc_val: 0.5540 time: 2.2482s 126 349\n",
            "Epoch: 0155 loss_train: 1.3654 acc_train: 0.6120 loss_val: 2.1673 acc_val: 0.5580 time: 2.2608s 314 408\n",
            "Epoch: 0156 loss_train: 1.4002 acc_train: 0.6000 loss_val: 2.1586 acc_val: 0.5520 time: 2.2724s 329 286\n",
            "Epoch: 0157 loss_train: 1.3707 acc_train: 0.6180 loss_val: 2.1632 acc_val: 0.5480 time: 2.2841s 377 466\n",
            "Epoch: 0158 loss_train: 1.3706 acc_train: 0.6080 loss_val: 2.1659 acc_val: 0.5460 time: 2.2955s 262 235\n",
            "Epoch: 0159 loss_train: 1.3878 acc_train: 0.6040 loss_val: 2.1689 acc_val: 0.5440 time: 2.3073s 462 263\n",
            "Epoch: 0160 loss_train: 1.3690 acc_train: 0.6160 loss_val: 2.1661 acc_val: 0.5460 time: 2.3191s 380 429\n",
            "Epoch: 0161 loss_train: 1.3942 acc_train: 0.6040 loss_val: 2.1933 acc_val: 0.5440 time: 2.3330s 261 202\n",
            "Epoch: 0162 loss_train: 1.3486 acc_train: 0.6240 loss_val: 2.2366 acc_val: 0.5360 time: 2.3459s 242 139\n",
            "Epoch: 0163 loss_train: 1.3912 acc_train: 0.6160 loss_val: 2.2788 acc_val: 0.5320 time: 2.3587s 430 364\n",
            "Epoch: 0164 loss_train: 1.3520 acc_train: 0.6160 loss_val: 2.3039 acc_val: 0.5380 time: 2.3714s 217 407\n",
            "Epoch: 0165 loss_train: 1.4007 acc_train: 0.6100 loss_val: 2.3091 acc_val: 0.5400 time: 2.3832s 427 168\n",
            "Epoch: 0166 loss_train: 1.3957 acc_train: 0.6060 loss_val: 2.2888 acc_val: 0.5480 time: 2.3952s 129 398\n",
            "Epoch: 0167 loss_train: 1.3600 acc_train: 0.6140 loss_val: 2.2532 acc_val: 0.5500 time: 2.4077s 342 187\n",
            "Epoch: 0168 loss_train: 1.3756 acc_train: 0.6180 loss_val: 2.2287 acc_val: 0.5580 time: 2.4199s 110 402\n",
            "Epoch: 0169 loss_train: 1.4065 acc_train: 0.5920 loss_val: 2.2315 acc_val: 0.5560 time: 2.4324s 479 117\n",
            "Epoch: 0170 loss_train: 1.3917 acc_train: 0.6160 loss_val: 2.2224 acc_val: 0.5540 time: 2.4449s 404 242\n",
            "Epoch: 0171 loss_train: 1.3972 acc_train: 0.6100 loss_val: 2.2071 acc_val: 0.5540 time: 2.4579s 379 422\n",
            "Epoch: 0172 loss_train: 1.3795 acc_train: 0.6140 loss_val: 2.2035 acc_val: 0.5420 time: 2.4723s 408 484\n",
            "Epoch: 0173 loss_train: 1.4069 acc_train: 0.5720 loss_val: 2.1974 acc_val: 0.5400 time: 2.4881s 157 415\n",
            "Epoch: 0174 loss_train: 1.4110 acc_train: 0.5820 loss_val: 2.1869 acc_val: 0.5360 time: 2.5037s 266 113\n",
            "Epoch: 0175 loss_train: 1.3772 acc_train: 0.6080 loss_val: 2.1447 acc_val: 0.5360 time: 2.5172s 486 248\n",
            "Epoch: 0176 loss_train: 1.4153 acc_train: 0.5900 loss_val: 2.1300 acc_val: 0.5440 time: 2.5318s 487 210\n",
            "Epoch: 0177 loss_train: 1.3854 acc_train: 0.5940 loss_val: 2.1413 acc_val: 0.5420 time: 2.5480s 297 468\n",
            "Epoch: 0178 loss_train: 1.3845 acc_train: 0.5980 loss_val: 2.1606 acc_val: 0.5340 time: 2.5616s 294 303\n",
            "Epoch: 0179 loss_train: 1.3971 acc_train: 0.5940 loss_val: 2.1856 acc_val: 0.5320 time: 2.5750s 412 250\n",
            "Epoch: 0180 loss_train: 1.4049 acc_train: 0.5920 loss_val: 2.1998 acc_val: 0.5280 time: 2.5873s 186 373\n",
            "Epoch: 0181 loss_train: 1.4215 acc_train: 0.5760 loss_val: 2.1427 acc_val: 0.5240 time: 2.6000s 170 144\n",
            "Epoch: 0182 loss_train: 1.4044 acc_train: 0.5920 loss_val: 2.0974 acc_val: 0.5240 time: 2.6145s 240 343\n",
            "Epoch: 0183 loss_train: 1.4012 acc_train: 0.5960 loss_val: 2.0992 acc_val: 0.5320 time: 2.6283s 274 362\n",
            "Epoch: 0184 loss_train: 1.4279 acc_train: 0.5800 loss_val: 2.1074 acc_val: 0.5300 time: 2.6413s 376 372\n",
            "Epoch: 0185 loss_train: 1.4065 acc_train: 0.5960 loss_val: 2.1724 acc_val: 0.5280 time: 2.6566s 389 478\n",
            "Epoch: 0186 loss_train: 1.4158 acc_train: 0.5960 loss_val: 2.2900 acc_val: 0.5220 time: 2.6715s 303 154\n",
            "Epoch: 0187 loss_train: 1.3797 acc_train: 0.5920 loss_val: 2.3989 acc_val: 0.5180 time: 2.6869s 470 222\n",
            "Epoch: 0188 loss_train: 1.3944 acc_train: 0.5800 loss_val: 2.4861 acc_val: 0.5160 time: 2.7003s 322 485\n",
            "Epoch: 0189 loss_train: 1.4075 acc_train: 0.5720 loss_val: 2.5209 acc_val: 0.5140 time: 2.7131s 280 279\n",
            "Epoch: 0190 loss_train: 1.4109 acc_train: 0.5800 loss_val: 2.5294 acc_val: 0.5120 time: 2.7266s 387 493\n",
            "Epoch: 0191 loss_train: 1.4101 acc_train: 0.5780 loss_val: 2.4990 acc_val: 0.5160 time: 2.7419s 485 392\n",
            "Epoch: 0192 loss_train: 1.4208 acc_train: 0.5680 loss_val: 2.4758 acc_val: 0.5200 time: 2.7568s 391 426\n",
            "Epoch: 0193 loss_train: 1.4027 acc_train: 0.5860 loss_val: 2.4528 acc_val: 0.5120 time: 2.7719s 218 128\n",
            "Epoch: 0194 loss_train: 1.4147 acc_train: 0.5820 loss_val: 2.4035 acc_val: 0.5080 time: 2.7868s 463 255\n",
            "Epoch: 0195 loss_train: 1.3914 acc_train: 0.5660 loss_val: 2.3513 acc_val: 0.5080 time: 2.8023s 134 292\n",
            "Epoch: 0196 loss_train: 1.4152 acc_train: 0.5780 loss_val: 2.3294 acc_val: 0.5060 time: 2.8164s 161 377\n",
            "Epoch: 0197 loss_train: 1.4135 acc_train: 0.5740 loss_val: 2.2822 acc_val: 0.5020 time: 2.8322s 293 330\n",
            "Epoch: 0198 loss_train: 1.4143 acc_train: 0.5680 loss_val: 2.2752 acc_val: 0.4980 time: 2.8466s 474 223\n",
            "Epoch: 0199 loss_train: 1.4091 acc_train: 0.5680 loss_val: 2.2709 acc_val: 0.5000 time: 2.8614s 158 239\n",
            "Epoch: 0200 loss_train: 1.3939 acc_train: 0.5780 loss_val: 2.2897 acc_val: 0.4960 time: 2.8743s 419 219\n",
            "Epoch: 0201 loss_train: 1.4118 acc_train: 0.5860 loss_val: 2.3257 acc_val: 0.5000 time: 2.8874s 331 458\n",
            "Epoch: 0202 loss_train: 1.4049 acc_train: 0.5600 loss_val: 2.4015 acc_val: 0.5040 time: 2.9025s 369 295\n",
            "Epoch: 0203 loss_train: 1.4100 acc_train: 0.5760 loss_val: 2.4745 acc_val: 0.5020 time: 2.9148s 112 419\n",
            "Epoch: 0204 loss_train: 1.3980 acc_train: 0.5740 loss_val: 2.5278 acc_val: 0.4980 time: 2.9302s 344 412\n",
            "Epoch: 0205 loss_train: 1.4426 acc_train: 0.5720 loss_val: 2.5644 acc_val: 0.5040 time: 2.9438s 122 413\n",
            "Epoch: 0206 loss_train: 1.4115 acc_train: 0.5680 loss_val: 2.5619 acc_val: 0.5160 time: 2.9624s 484 386\n",
            "Epoch: 0207 loss_train: 1.3959 acc_train: 0.5740 loss_val: 2.5134 acc_val: 0.5220 time: 2.9789s 407 479\n",
            "Epoch: 0208 loss_train: 1.4131 acc_train: 0.5680 loss_val: 2.4525 acc_val: 0.5260 time: 2.9951s 105 370\n",
            "Epoch: 0209 loss_train: 1.4276 acc_train: 0.5660 loss_val: 2.4002 acc_val: 0.5200 time: 3.0096s 149 371\n",
            "Epoch: 0210 loss_train: 1.4045 acc_train: 0.5640 loss_val: 2.3548 acc_val: 0.5120 time: 3.0228s 292 436\n",
            "Epoch: 0211 loss_train: 1.4237 acc_train: 0.5780 loss_val: 2.3081 acc_val: 0.5020 time: 3.0367s 390 450\n",
            "Epoch: 0212 loss_train: 1.4017 acc_train: 0.5680 loss_val: 2.2933 acc_val: 0.5020 time: 3.0501s 464 212\n",
            "Epoch: 0213 loss_train: 1.4175 acc_train: 0.5500 loss_val: 2.2993 acc_val: 0.4940 time: 3.0653s 341 156\n",
            "Epoch: 0214 loss_train: 1.4287 acc_train: 0.5520 loss_val: 2.3181 acc_val: 0.4920 time: 3.0785s 375 270\n",
            "Epoch: 0215 loss_train: 1.4199 acc_train: 0.5680 loss_val: 2.3566 acc_val: 0.4960 time: 3.0922s 298 259\n",
            "Epoch: 0216 loss_train: 1.4137 acc_train: 0.5440 loss_val: 2.3934 acc_val: 0.5040 time: 3.1041s 265 309\n",
            "Epoch: 0217 loss_train: 1.4026 acc_train: 0.5620 loss_val: 2.4383 acc_val: 0.5020 time: 3.1171s 360 329\n",
            "Epoch: 0218 loss_train: 1.4210 acc_train: 0.5660 loss_val: 2.3695 acc_val: 0.4980 time: 3.1299s 153 461\n",
            "Epoch: 0219 loss_train: 1.4213 acc_train: 0.5480 loss_val: 2.3253 acc_val: 0.4940 time: 3.1441s 374 379\n",
            "Epoch: 0220 loss_train: 1.4172 acc_train: 0.5560 loss_val: 2.3126 acc_val: 0.4880 time: 3.1577s 483 193\n",
            "Epoch: 0221 loss_train: 1.4342 acc_train: 0.5460 loss_val: 2.3327 acc_val: 0.4920 time: 3.1737s 296 310\n",
            "Epoch: 0222 loss_train: 1.4369 acc_train: 0.5520 loss_val: 2.3642 acc_val: 0.4900 time: 3.1865s 321 302\n",
            "Epoch: 0223 loss_train: 1.4193 acc_train: 0.5460 loss_val: 2.4034 acc_val: 0.4880 time: 3.2005s 397 327\n",
            "Epoch: 0224 loss_train: 1.4122 acc_train: 0.5500 loss_val: 2.4434 acc_val: 0.4880 time: 3.2143s 460 494\n",
            "Epoch: 0225 loss_train: 1.4444 acc_train: 0.5540 loss_val: 2.5103 acc_val: 0.4860 time: 3.2267s 312 459\n",
            "Epoch: 0226 loss_train: 1.3935 acc_train: 0.5740 loss_val: 2.5560 acc_val: 0.4860 time: 3.2398s 258 175\n",
            "Epoch: 0227 loss_train: 1.3971 acc_train: 0.5480 loss_val: 2.5948 acc_val: 0.4920 time: 3.2529s 209 420\n",
            "Epoch: 0228 loss_train: 1.4364 acc_train: 0.5440 loss_val: 2.5923 acc_val: 0.4900 time: 3.2666s 241 404\n",
            "Epoch: 0229 loss_train: 1.4092 acc_train: 0.5520 loss_val: 2.5217 acc_val: 0.4920 time: 3.2807s 365 120\n",
            "Epoch: 0230 loss_train: 1.4345 acc_train: 0.5280 loss_val: 2.4287 acc_val: 0.4900 time: 3.2942s 323 374\n",
            "Epoch: 0231 loss_train: 1.3990 acc_train: 0.5420 loss_val: 2.3673 acc_val: 0.4920 time: 3.3073s 334 143\n",
            "Epoch: 0232 loss_train: 1.4297 acc_train: 0.5420 loss_val: 2.3170 acc_val: 0.4940 time: 3.3193s 326 110\n",
            "Epoch: 0233 loss_train: 1.3946 acc_train: 0.5560 loss_val: 2.2876 acc_val: 0.4900 time: 3.3314s 413 350\n",
            "Epoch: 0234 loss_train: 1.4447 acc_train: 0.5540 loss_val: 2.2828 acc_val: 0.4860 time: 3.3435s 409 317\n",
            "Epoch: 0235 loss_train: 1.4205 acc_train: 0.5540 loss_val: 2.3003 acc_val: 0.4860 time: 3.3570s 317 189\n",
            "Epoch: 0236 loss_train: 1.4137 acc_train: 0.5460 loss_val: 2.3274 acc_val: 0.4780 time: 3.3705s 371 132\n",
            "Epoch: 0237 loss_train: 1.4045 acc_train: 0.5540 loss_val: 2.3523 acc_val: 0.4840 time: 3.3875s 194 423\n",
            "Epoch: 0238 loss_train: 1.4769 acc_train: 0.5480 loss_val: 2.2408 acc_val: 0.4920 time: 3.4026s 343 170\n",
            "Epoch: 0239 loss_train: 1.3917 acc_train: 0.5460 loss_val: 2.1458 acc_val: 0.4920 time: 3.4170s 308 396\n",
            "Epoch: 0240 loss_train: 1.4336 acc_train: 0.5260 loss_val: 2.1336 acc_val: 0.4920 time: 3.4308s 356 306\n",
            "Epoch: 0241 loss_train: 1.4123 acc_train: 0.5440 loss_val: 2.1223 acc_val: 0.4900 time: 3.4459s 429 406\n",
            "Epoch: 0242 loss_train: 1.4070 acc_train: 0.5420 loss_val: 2.0913 acc_val: 0.4860 time: 3.4594s 239 464\n",
            "Epoch: 0243 loss_train: 1.4272 acc_train: 0.5340 loss_val: 2.1065 acc_val: 0.4840 time: 3.4737s 327 234\n",
            "Epoch: 0244 loss_train: 1.4446 acc_train: 0.5060 loss_val: 2.1338 acc_val: 0.4820 time: 3.4869s 353 162\n",
            "Epoch: 0245 loss_train: 1.4068 acc_train: 0.5500 loss_val: 2.1561 acc_val: 0.4840 time: 3.5005s 289 137\n",
            "Epoch: 0246 loss_train: 1.4173 acc_train: 0.5500 loss_val: 2.1022 acc_val: 0.4840 time: 3.5143s 288 340\n",
            "Epoch: 0247 loss_train: 1.4229 acc_train: 0.5360 loss_val: 2.1122 acc_val: 0.4760 time: 3.5272s 179 245\n",
            "Epoch: 0248 loss_train: 1.4025 acc_train: 0.5280 loss_val: 2.1036 acc_val: 0.4720 time: 3.5407s 301 446\n",
            "Epoch: 0249 loss_train: 1.4246 acc_train: 0.5300 loss_val: 2.1187 acc_val: 0.4800 time: 3.5546s 206 300\n",
            "Epoch: 0250 loss_train: 1.4220 acc_train: 0.5340 loss_val: 2.2091 acc_val: 0.4760 time: 3.5697s 282 190\n",
            "Epoch: 0251 loss_train: 1.4272 acc_train: 0.5200 loss_val: 2.2861 acc_val: 0.4820 time: 3.5827s 417 315\n",
            "Epoch: 0252 loss_train: 1.4141 acc_train: 0.5340 loss_val: 2.3810 acc_val: 0.4800 time: 3.6002s 347 122\n",
            "Epoch: 0253 loss_train: 1.4485 acc_train: 0.5280 loss_val: 2.4751 acc_val: 0.4800 time: 3.6154s 399 276\n",
            "Epoch: 0254 loss_train: 1.4196 acc_train: 0.5240 loss_val: 2.5435 acc_val: 0.4740 time: 3.6279s 310 129\n",
            "Epoch: 0255 loss_train: 1.4171 acc_train: 0.5440 loss_val: 2.5471 acc_val: 0.4700 time: 3.6406s 150 381\n",
            "Epoch: 0256 loss_train: 1.4288 acc_train: 0.5300 loss_val: 2.5065 acc_val: 0.4680 time: 3.6534s 154 241\n",
            "Epoch: 0257 loss_train: 1.4405 acc_train: 0.5380 loss_val: 2.4515 acc_val: 0.4680 time: 3.6695s 178 351\n",
            "Epoch: 0258 loss_train: 1.4317 acc_train: 0.5120 loss_val: 2.3908 acc_val: 0.4680 time: 3.6840s 366 274\n",
            "Epoch: 0259 loss_train: 1.4005 acc_train: 0.5240 loss_val: 2.3183 acc_val: 0.4700 time: 3.6979s 255 378\n",
            "Epoch: 0260 loss_train: 1.4007 acc_train: 0.5360 loss_val: 2.2674 acc_val: 0.4620 time: 3.7123s 287 492\n",
            "Epoch: 0261 loss_train: 1.4325 acc_train: 0.5300 loss_val: 2.2548 acc_val: 0.4580 time: 3.7252s 467 230\n",
            "Epoch: 0262 loss_train: 1.4131 acc_train: 0.5320 loss_val: 2.2763 acc_val: 0.4560 time: 3.7394s 230 491\n",
            "Epoch: 0263 loss_train: 1.4507 acc_train: 0.5180 loss_val: 2.3097 acc_val: 0.4520 time: 3.7530s 386 184\n",
            "Epoch: 0264 loss_train: 1.4008 acc_train: 0.5360 loss_val: 2.3509 acc_val: 0.4440 time: 3.7679s 216 103\n",
            "Epoch: 0265 loss_train: 1.4575 acc_train: 0.5080 loss_val: 2.3917 acc_val: 0.4420 time: 3.7824s 451 114\n",
            "Epoch: 0266 loss_train: 1.4138 acc_train: 0.5240 loss_val: 2.4081 acc_val: 0.4520 time: 3.7967s 200 411\n",
            "Epoch: 0267 loss_train: 1.4239 acc_train: 0.5200 loss_val: 2.4536 acc_val: 0.4500 time: 3.8157s 304 228\n",
            "Epoch: 0268 loss_train: 1.4452 acc_train: 0.5000 loss_val: 2.4888 acc_val: 0.4560 time: 3.8289s 488 124\n",
            "Epoch: 0269 loss_train: 1.4599 acc_train: 0.5160 loss_val: 2.5391 acc_val: 0.4540 time: 3.8417s 453 301\n",
            "Epoch: 0270 loss_train: 1.4846 acc_train: 0.4980 loss_val: 2.5809 acc_val: 0.4540 time: 3.8554s 160 489\n",
            "Epoch: 0271 loss_train: 1.4626 acc_train: 0.4980 loss_val: 2.5527 acc_val: 0.4500 time: 3.8697s 466 288\n",
            "Epoch: 0272 loss_train: 1.4747 acc_train: 0.4900 loss_val: 2.5406 acc_val: 0.4460 time: 3.8864s 146 275\n",
            "Epoch: 0273 loss_train: 1.4699 acc_train: 0.5000 loss_val: 2.5195 acc_val: 0.4400 time: 3.9012s 497 257\n",
            "Epoch: 0274 loss_train: 1.4476 acc_train: 0.5020 loss_val: 2.5400 acc_val: 0.4340 time: 3.9149s 152 135\n",
            "Epoch: 0275 loss_train: 1.4567 acc_train: 0.5000 loss_val: 2.5457 acc_val: 0.4400 time: 3.9289s 101 249\n",
            "Epoch: 0276 loss_train: 1.4270 acc_train: 0.5180 loss_val: 2.5628 acc_val: 0.4340 time: 3.9437s 207 434\n",
            "Epoch: 0277 loss_train: 1.4793 acc_train: 0.5160 loss_val: 2.5797 acc_val: 0.4340 time: 3.9588s 271 496\n",
            "Epoch: 0278 loss_train: 1.4188 acc_train: 0.5240 loss_val: 2.6020 acc_val: 0.4380 time: 3.9724s 431 336\n",
            "Epoch: 0279 loss_train: 1.4548 acc_train: 0.5080 loss_val: 2.6213 acc_val: 0.4400 time: 3.9858s 446 221\n",
            "Epoch: 0280 loss_train: 1.4583 acc_train: 0.5000 loss_val: 2.6179 acc_val: 0.4400 time: 4.0000s 114 480\n",
            "Epoch: 0281 loss_train: 1.4239 acc_train: 0.5240 loss_val: 2.6024 acc_val: 0.4360 time: 4.0159s 433 342\n",
            "Epoch: 0282 loss_train: 1.4724 acc_train: 0.4700 loss_val: 2.5723 acc_val: 0.4320 time: 4.0320s 437 383\n",
            "Epoch: 0283 loss_train: 1.4104 acc_train: 0.5240 loss_val: 2.5308 acc_val: 0.4280 time: 4.0457s 330 133\n",
            "Epoch: 0284 loss_train: 1.4342 acc_train: 0.5020 loss_val: 2.5138 acc_val: 0.4260 time: 4.0587s 252 112\n",
            "Epoch: 0285 loss_train: 1.4702 acc_train: 0.4840 loss_val: 2.5084 acc_val: 0.4280 time: 4.0739s 422 198\n",
            "Epoch: 0286 loss_train: 1.4762 acc_train: 0.4760 loss_val: 2.4922 acc_val: 0.4220 time: 4.0904s 448 339\n",
            "Epoch: 0287 loss_train: 1.4482 acc_train: 0.4860 loss_val: 2.4955 acc_val: 0.4280 time: 4.1041s 441 100\n",
            "Epoch: 0288 loss_train: 1.4502 acc_train: 0.5120 loss_val: 2.5161 acc_val: 0.4260 time: 4.1172s 159 367\n",
            "Epoch: 0289 loss_train: 1.4842 acc_train: 0.4820 loss_val: 2.5503 acc_val: 0.4260 time: 4.1305s 421 127\n",
            "Epoch: 0290 loss_train: 1.4916 acc_train: 0.4860 loss_val: 2.6054 acc_val: 0.4300 time: 4.1437s 381 171\n",
            "Epoch: 0291 loss_train: 1.4359 acc_train: 0.4960 loss_val: 2.6659 acc_val: 0.4200 time: 4.1569s 436 427\n",
            "Epoch: 0292 loss_train: 1.4647 acc_train: 0.5020 loss_val: 2.7050 acc_val: 0.4180 time: 4.1706s 128 218\n",
            "Epoch: 0293 loss_train: 1.4496 acc_train: 0.5020 loss_val: 2.7243 acc_val: 0.4260 time: 4.1836s 246 148\n",
            "Epoch: 0294 loss_train: 1.4636 acc_train: 0.4980 loss_val: 2.7303 acc_val: 0.4240 time: 4.1974s 113 442\n",
            "Epoch: 0295 loss_train: 1.4330 acc_train: 0.5280 loss_val: 2.5911 acc_val: 0.4240 time: 4.2113s 171 192\n",
            "Epoch: 0296 loss_train: 1.4452 acc_train: 0.4900 loss_val: 2.4857 acc_val: 0.4320 time: 4.2295s 476 294\n",
            "Epoch: 0297 loss_train: 1.4541 acc_train: 0.5080 loss_val: 2.4184 acc_val: 0.4360 time: 4.2431s 175 277\n",
            "Epoch: 0298 loss_train: 1.4867 acc_train: 0.4700 loss_val: 2.3299 acc_val: 0.4280 time: 4.2576s 318 151\n",
            "Epoch: 0299 loss_train: 1.4743 acc_train: 0.4820 loss_val: 2.2698 acc_val: 0.4240 time: 4.2753s 332 116\n",
            "Epoch: 0300 loss_train: 1.4286 acc_train: 0.5120 loss_val: 2.2611 acc_val: 0.4280 time: 4.2892s 411 409\n",
            "Epoch: 0301 loss_train: 1.4442 acc_train: 0.5020 loss_val: 2.3024 acc_val: 0.4260 time: 4.3054s 472 153\n",
            "Epoch: 0302 loss_train: 1.4475 acc_train: 0.5160 loss_val: 2.3795 acc_val: 0.4240 time: 4.3190s 305 269\n",
            "Epoch: 0303 loss_train: 1.4381 acc_train: 0.5040 loss_val: 2.4613 acc_val: 0.4200 time: 4.3352s 468 304\n",
            "Epoch: 0304 loss_train: 1.4289 acc_train: 0.5040 loss_val: 2.5577 acc_val: 0.4200 time: 4.3477s 189 261\n",
            "Epoch: 0305 loss_train: 1.4609 acc_train: 0.4800 loss_val: 2.6314 acc_val: 0.4260 time: 4.3611s 106 338\n",
            "Epoch: 0306 loss_train: 1.5015 acc_train: 0.4800 loss_val: 2.5711 acc_val: 0.4200 time: 4.3742s 281 375\n",
            "Epoch: 0307 loss_train: 1.5054 acc_train: 0.4880 loss_val: 2.5201 acc_val: 0.4120 time: 4.3867s 393 366\n",
            "Epoch: 0308 loss_train: 1.4981 acc_train: 0.4740 loss_val: 2.4777 acc_val: 0.4020 time: 4.3994s 193 410\n",
            "Epoch: 0309 loss_train: 1.4762 acc_train: 0.5060 loss_val: 2.3871 acc_val: 0.3980 time: 4.4117s 169 205\n",
            "Epoch: 0310 loss_train: 1.4618 acc_train: 0.5000 loss_val: 2.3525 acc_val: 0.3920 time: 4.4239s 190 111\n",
            "Epoch: 0311 loss_train: 1.5199 acc_train: 0.4520 loss_val: 2.3433 acc_val: 0.3900 time: 4.4405s 290 346\n",
            "Epoch: 0312 loss_train: 1.5068 acc_train: 0.4700 loss_val: 2.3358 acc_val: 0.3860 time: 4.4527s 155 322\n",
            "Epoch: 0313 loss_train: 1.4811 acc_train: 0.4840 loss_val: 2.3360 acc_val: 0.3860 time: 4.4645s 177 356\n",
            "Epoch: 0314 loss_train: 1.4809 acc_train: 0.4600 loss_val: 2.3825 acc_val: 0.3880 time: 4.4761s 392 174\n",
            "Epoch: 0315 loss_train: 1.4674 acc_train: 0.4740 loss_val: 2.4379 acc_val: 0.3960 time: 4.4899s 302 258\n",
            "Epoch: 0316 loss_train: 1.4783 acc_train: 0.4720 loss_val: 2.4922 acc_val: 0.4000 time: 4.5020s 338 498\n",
            "Epoch: 0317 loss_train: 1.4488 acc_train: 0.4900 loss_val: 2.5390 acc_val: 0.4100 time: 4.5162s 185 454\n",
            "Epoch: 0318 loss_train: 1.4492 acc_train: 0.5080 loss_val: 2.5216 acc_val: 0.4120 time: 4.5296s 165 435\n",
            "Epoch: 0319 loss_train: 1.4274 acc_train: 0.5100 loss_val: 2.5096 acc_val: 0.4120 time: 4.5463s 138 332\n",
            "Epoch: 0320 loss_train: 1.4414 acc_train: 0.4820 loss_val: 2.6070 acc_val: 0.4160 time: 4.5606s 364 165\n",
            "Epoch: 0321 loss_train: 1.4779 acc_train: 0.4840 loss_val: 2.6748 acc_val: 0.4160 time: 4.5734s 316 272\n",
            "Epoch: 0322 loss_train: 1.5397 acc_train: 0.4380 loss_val: 2.7143 acc_val: 0.4080 time: 4.5861s 368 101\n",
            "Epoch: 0323 loss_train: 1.4842 acc_train: 0.4860 loss_val: 2.6873 acc_val: 0.4120 time: 4.5988s 319 188\n",
            "Epoch: 0324 loss_train: 1.4566 acc_train: 0.4800 loss_val: 2.6343 acc_val: 0.4000 time: 4.6116s 498 214\n",
            "Epoch: 0325 loss_train: 1.4505 acc_train: 0.4680 loss_val: 2.5861 acc_val: 0.3900 time: 4.6249s 284 388\n",
            "Epoch: 0326 loss_train: 1.4505 acc_train: 0.4880 loss_val: 2.5323 acc_val: 0.3780 time: 4.6395s 173 233\n",
            "Epoch: 0327 loss_train: 1.4572 acc_train: 0.4940 loss_val: 2.4912 acc_val: 0.3760 time: 4.6558s 307 291\n",
            "Epoch: 0328 loss_train: 1.4631 acc_train: 0.4660 loss_val: 2.4647 acc_val: 0.3720 time: 4.6687s 475 418\n",
            "Epoch: 0329 loss_train: 1.4781 acc_train: 0.4740 loss_val: 2.4965 acc_val: 0.3740 time: 4.6821s 238 337\n",
            "Epoch: 0330 loss_train: 1.4720 acc_train: 0.4760 loss_val: 2.5552 acc_val: 0.3740 time: 4.6965s 247 183\n",
            "Epoch: 0331 loss_train: 1.4545 acc_train: 0.4780 loss_val: 2.5566 acc_val: 0.3640 time: 4.7098s 118 181\n",
            "Epoch: 0332 loss_train: 1.4583 acc_train: 0.4560 loss_val: 2.5560 acc_val: 0.3720 time: 4.7221s 473 131\n",
            "Epoch: 0333 loss_train: 1.4757 acc_train: 0.4740 loss_val: 2.5397 acc_val: 0.3740 time: 4.7350s 494 209\n",
            "Epoch: 0334 loss_train: 1.5044 acc_train: 0.4840 loss_val: 2.5709 acc_val: 0.3720 time: 4.7475s 401 483\n",
            "Epoch: 0335 loss_train: 1.4430 acc_train: 0.4880 loss_val: 2.5861 acc_val: 0.3780 time: 4.7631s 445 416\n",
            "Epoch: 0336 loss_train: 1.4858 acc_train: 0.4700 loss_val: 2.5896 acc_val: 0.3780 time: 4.7776s 478 345\n",
            "Epoch: 0337 loss_train: 1.4768 acc_train: 0.4660 loss_val: 2.6147 acc_val: 0.3820 time: 4.7908s 383 452\n",
            "Epoch: 0338 loss_train: 1.4420 acc_train: 0.4980 loss_val: 2.6603 acc_val: 0.4000 time: 4.8054s 181 382\n",
            "Epoch: 0339 loss_train: 1.4603 acc_train: 0.4840 loss_val: 2.7107 acc_val: 0.3980 time: 4.8189s 219 296\n",
            "Epoch: 0340 loss_train: 1.4398 acc_train: 0.4880 loss_val: 2.7217 acc_val: 0.4060 time: 4.8322s 452 318\n",
            "Epoch: 0341 loss_train: 1.5081 acc_train: 0.4560 loss_val: 2.6800 acc_val: 0.4120 time: 4.8461s 306 108\n",
            "Epoch: 0342 loss_train: 1.4503 acc_train: 0.4760 loss_val: 2.7270 acc_val: 0.4080 time: 4.8696s 357 447\n",
            "Epoch: 0343 loss_train: 1.4821 acc_train: 0.4540 loss_val: 2.5926 acc_val: 0.3940 time: 4.8893s 469 155\n",
            "Epoch: 0344 loss_train: 1.4897 acc_train: 0.4760 loss_val: 2.4265 acc_val: 0.3860 time: 4.9029s 320 358\n",
            "Epoch: 0345 loss_train: 1.4939 acc_train: 0.4520 loss_val: 2.2799 acc_val: 0.3780 time: 4.9220s 378 414\n",
            "Epoch: 0346 loss_train: 1.4873 acc_train: 0.4840 loss_val: 2.2275 acc_val: 0.3720 time: 4.9358s 286 417\n",
            "Epoch: 0347 loss_train: 1.4498 acc_train: 0.4780 loss_val: 2.2082 acc_val: 0.3720 time: 4.9514s 400 149\n",
            "Epoch: 0348 loss_train: 1.4625 acc_train: 0.4740 loss_val: 2.2274 acc_val: 0.3740 time: 4.9720s 395 141\n",
            "Epoch: 0349 loss_train: 1.4723 acc_train: 0.4640 loss_val: 2.2844 acc_val: 0.3760 time: 4.9862s 133 287\n",
            "Epoch: 0350 loss_train: 1.4816 acc_train: 0.4520 loss_val: 2.3557 acc_val: 0.3740 time: 4.9995s 361 325\n",
            "Epoch: 0351 loss_train: 1.4624 acc_train: 0.4580 loss_val: 2.4533 acc_val: 0.3720 time: 5.0201s 311 123\n",
            "Epoch: 0352 loss_train: 1.4691 acc_train: 0.4680 loss_val: 2.5449 acc_val: 0.3940 time: 5.0331s 131 323\n",
            "Epoch: 0353 loss_train: 1.4519 acc_train: 0.4600 loss_val: 2.5676 acc_val: 0.3960 time: 5.0469s 108 186\n",
            "Epoch: 0354 loss_train: 1.4480 acc_train: 0.4880 loss_val: 2.5713 acc_val: 0.3940 time: 5.0649s 221 431\n",
            "Epoch: 0355 loss_train: 1.4790 acc_train: 0.4420 loss_val: 2.6193 acc_val: 0.3960 time: 5.0832s 355 355\n",
            "Epoch: 0356 loss_train: 1.4631 acc_train: 0.4760 loss_val: 2.6088 acc_val: 0.3920 time: 5.0989s 196 467\n",
            "Epoch: 0357 loss_train: 1.4544 acc_train: 0.4700 loss_val: 2.5614 acc_val: 0.3940 time: 5.1120s 145 314\n",
            "Epoch: 0358 loss_train: 1.4423 acc_train: 0.4760 loss_val: 2.5552 acc_val: 0.3900 time: 5.1276s 270 472\n",
            "Epoch: 0359 loss_train: 1.4488 acc_train: 0.4660 loss_val: 2.5323 acc_val: 0.3940 time: 5.1442s 267 213\n",
            "Epoch: 0360 loss_train: 1.4415 acc_train: 0.4620 loss_val: 2.5154 acc_val: 0.3840 time: 5.1575s 295 471\n",
            "Epoch: 0361 loss_train: 1.4145 acc_train: 0.4960 loss_val: 2.5194 acc_val: 0.3940 time: 5.1709s 124 283\n",
            "Epoch: 0362 loss_train: 1.4723 acc_train: 0.4660 loss_val: 2.5195 acc_val: 0.4000 time: 5.1877s 273 142\n",
            "Epoch: 0363 loss_train: 1.4634 acc_train: 0.5020 loss_val: 2.5211 acc_val: 0.4000 time: 5.2018s 115 432\n",
            "Epoch: 0364 loss_train: 1.4749 acc_train: 0.4720 loss_val: 2.5337 acc_val: 0.3980 time: 5.2164s 201 451\n",
            "Epoch: 0365 loss_train: 1.4410 acc_train: 0.4720 loss_val: 2.5683 acc_val: 0.4000 time: 5.2334s 272 425\n",
            "Epoch: 0366 loss_train: 1.4617 acc_train: 0.4680 loss_val: 2.6104 acc_val: 0.4040 time: 5.2466s 254 267\n",
            "Epoch: 0367 loss_train: 1.4586 acc_train: 0.4740 loss_val: 2.6583 acc_val: 0.4040 time: 5.2605s 211 299\n",
            "Epoch: 0368 loss_train: 1.4638 acc_train: 0.4880 loss_val: 2.6827 acc_val: 0.4100 time: 5.2783s 410 441\n",
            "Epoch: 0369 loss_train: 1.4606 acc_train: 0.5000 loss_val: 2.6994 acc_val: 0.4180 time: 5.2993s 187 196\n",
            "Epoch: 0370 loss_train: 1.4619 acc_train: 0.4620 loss_val: 2.7231 acc_val: 0.4200 time: 5.3169s 156 437\n",
            "Epoch: 0371 loss_train: 1.4336 acc_train: 0.4880 loss_val: 2.7509 acc_val: 0.4140 time: 5.3300s 275 453\n",
            "Epoch: 0372 loss_train: 1.4146 acc_train: 0.4820 loss_val: 2.7280 acc_val: 0.4140 time: 5.3436s 363 387\n",
            "Epoch: 0373 loss_train: 1.4468 acc_train: 0.4800 loss_val: 2.7009 acc_val: 0.4100 time: 5.3570s 139 394\n",
            "Epoch: 0374 loss_train: 1.4269 acc_train: 0.5100 loss_val: 2.6285 acc_val: 0.4020 time: 5.3737s 208 320\n",
            "Epoch: 0375 loss_train: 1.4063 acc_train: 0.5200 loss_val: 2.5498 acc_val: 0.3940 time: 5.3881s 123 399\n",
            "Epoch: 0376 loss_train: 1.4613 acc_train: 0.5040 loss_val: 2.5021 acc_val: 0.3940 time: 5.4013s 300 268\n",
            "Epoch: 0377 loss_train: 1.4151 acc_train: 0.5060 loss_val: 2.4858 acc_val: 0.4040 time: 5.4182s 420 232\n",
            "Epoch: 0378 loss_train: 1.4251 acc_train: 0.5020 loss_val: 2.4643 acc_val: 0.4020 time: 5.4327s 205 477\n",
            "Epoch: 0379 loss_train: 1.4375 acc_train: 0.5120 loss_val: 2.4556 acc_val: 0.4020 time: 5.4494s 132 177\n",
            "Epoch: 0380 loss_train: 1.4107 acc_train: 0.4960 loss_val: 2.4903 acc_val: 0.4140 time: 5.4721s 268 390\n",
            "Epoch: 0381 loss_train: 1.4487 acc_train: 0.4880 loss_val: 2.5437 acc_val: 0.4100 time: 5.4862s 434 439\n",
            "Epoch: 0382 loss_train: 1.4247 acc_train: 0.4980 loss_val: 2.6167 acc_val: 0.4040 time: 5.4996s 336 271\n",
            "Epoch: 0383 loss_train: 1.4650 acc_train: 0.4680 loss_val: 2.6180 acc_val: 0.3940 time: 5.5255s 253 107\n",
            "Epoch: 0384 loss_train: 1.4222 acc_train: 0.4980 loss_val: 2.6146 acc_val: 0.3900 time: 5.5397s 142 457\n",
            "Epoch: 0385 loss_train: 1.4181 acc_train: 0.4860 loss_val: 2.6070 acc_val: 0.3920 time: 5.5551s 237 333\n",
            "Epoch: 0386 loss_train: 1.4575 acc_train: 0.4720 loss_val: 2.6073 acc_val: 0.3900 time: 5.5730s 333 203\n",
            "Epoch: 0387 loss_train: 1.4369 acc_train: 0.4920 loss_val: 2.6007 acc_val: 0.4000 time: 5.5880s 440 136\n",
            "Epoch: 0388 loss_train: 1.4493 acc_train: 0.4720 loss_val: 2.5890 acc_val: 0.4040 time: 5.6051s 260 169\n",
            "Epoch: 0389 loss_train: 1.4184 acc_train: 0.4800 loss_val: 2.5435 acc_val: 0.4080 time: 5.6224s 335 224\n",
            "Epoch: 0390 loss_train: 1.4042 acc_train: 0.5160 loss_val: 2.5379 acc_val: 0.4200 time: 5.6375s 199 150\n",
            "Epoch: 0391 loss_train: 1.3881 acc_train: 0.5100 loss_val: 2.4996 acc_val: 0.4240 time: 5.6535s 256 376\n",
            "Epoch: 0392 loss_train: 1.4191 acc_train: 0.4980 loss_val: 2.4835 acc_val: 0.4240 time: 5.6697s 168 138\n",
            "Epoch: 0393 loss_train: 1.3983 acc_train: 0.5160 loss_val: 2.4779 acc_val: 0.4300 time: 5.6838s 309 102\n",
            "Epoch: 0394 loss_train: 1.4077 acc_train: 0.5000 loss_val: 2.4665 acc_val: 0.4320 time: 5.6968s 236 307\n",
            "Epoch: 0395 loss_train: 1.4254 acc_train: 0.4900 loss_val: 2.4792 acc_val: 0.4340 time: 5.7100s 394 191\n",
            "Epoch: 0396 loss_train: 1.4418 acc_train: 0.5020 loss_val: 2.4947 acc_val: 0.4380 time: 5.7226s 263 326\n",
            "Epoch: 0397 loss_train: 1.4371 acc_train: 0.4900 loss_val: 2.3081 acc_val: 0.4260 time: 5.7411s 141 360\n",
            "Epoch: 0398 loss_train: 1.4014 acc_train: 0.5160 loss_val: 2.3742 acc_val: 0.4200 time: 5.7546s 162 105\n",
            "Epoch: 0399 loss_train: 1.4125 acc_train: 0.5000 loss_val: 2.4128 acc_val: 0.4220 time: 5.7686s 203 324\n",
            "Epoch: 0400 loss_train: 1.4171 acc_train: 0.4960 loss_val: 2.3881 acc_val: 0.4260 time: 5.7834s 224 391\n",
            "Epoch: 0401 loss_train: 1.4074 acc_train: 0.5120 loss_val: 2.3593 acc_val: 0.4240 time: 5.7981s 0 0\n",
            "Epoch: 0402 loss_train: 1.4035 acc_train: 0.5000 loss_val: 2.3057 acc_val: 0.4280 time: 5.8116s 0 0\n",
            "Epoch: 0403 loss_train: 1.4008 acc_train: 0.5060 loss_val: 2.2584 acc_val: 0.4280 time: 5.8274s 0 0\n",
            "Epoch: 0404 loss_train: 1.4181 acc_train: 0.5020 loss_val: 2.2307 acc_val: 0.4400 time: 5.8415s 0 0\n",
            "Epoch: 0405 loss_train: 1.4000 acc_train: 0.5220 loss_val: 2.2136 acc_val: 0.4540 time: 5.8544s 0 0\n",
            "Epoch: 0406 loss_train: 1.3855 acc_train: 0.5300 loss_val: 2.3172 acc_val: 0.4580 time: 5.8679s 0 0\n",
            "Epoch: 0407 loss_train: 1.3950 acc_train: 0.5240 loss_val: 2.4279 acc_val: 0.4680 time: 5.8831s 0 0\n",
            "Epoch: 0408 loss_train: 1.4212 acc_train: 0.4900 loss_val: 2.4995 acc_val: 0.4660 time: 5.8971s 0 0\n",
            "Epoch: 0409 loss_train: 1.3946 acc_train: 0.5160 loss_val: 2.5551 acc_val: 0.4620 time: 5.9109s 0 0\n",
            "Epoch: 0410 loss_train: 1.3865 acc_train: 0.5420 loss_val: 2.6744 acc_val: 0.4580 time: 5.9235s 0 0\n",
            "Epoch: 0411 loss_train: 1.3929 acc_train: 0.5040 loss_val: 2.7071 acc_val: 0.4660 time: 5.9394s 0 0\n",
            "Epoch: 0412 loss_train: 1.3986 acc_train: 0.5040 loss_val: 2.6550 acc_val: 0.4700 time: 5.9543s 0 0\n",
            "Epoch: 0413 loss_train: 1.4103 acc_train: 0.5280 loss_val: 2.5745 acc_val: 0.4680 time: 5.9696s 0 0\n",
            "Epoch: 0414 loss_train: 1.3750 acc_train: 0.5340 loss_val: 2.4825 acc_val: 0.4700 time: 5.9830s 0 0\n",
            "Epoch: 0415 loss_train: 1.3902 acc_train: 0.5240 loss_val: 2.3992 acc_val: 0.4660 time: 5.9965s 0 0\n",
            "Epoch: 0416 loss_train: 1.3816 acc_train: 0.5260 loss_val: 2.2796 acc_val: 0.4580 time: 6.0100s 0 0\n",
            "Epoch: 0417 loss_train: 1.3526 acc_train: 0.5280 loss_val: 2.1944 acc_val: 0.4520 time: 6.0259s 0 0\n",
            "Epoch: 0418 loss_train: 1.3693 acc_train: 0.5240 loss_val: 2.1649 acc_val: 0.4500 time: 6.0422s 0 0\n",
            "Epoch: 0419 loss_train: 1.3955 acc_train: 0.5080 loss_val: 2.1466 acc_val: 0.4560 time: 6.0553s 0 0\n",
            "Epoch: 0420 loss_train: 1.3589 acc_train: 0.5260 loss_val: 2.1183 acc_val: 0.4580 time: 6.0694s 0 0\n",
            "Epoch: 0421 loss_train: 1.3668 acc_train: 0.5280 loss_val: 2.1112 acc_val: 0.4600 time: 6.0832s 0 0\n",
            "Epoch: 0422 loss_train: 1.3268 acc_train: 0.5500 loss_val: 2.1454 acc_val: 0.4620 time: 6.0981s 0 0\n",
            "Epoch: 0423 loss_train: 1.3912 acc_train: 0.4940 loss_val: 2.2288 acc_val: 0.4680 time: 6.1112s 0 0\n",
            "Epoch: 0424 loss_train: 1.3302 acc_train: 0.5440 loss_val: 2.2066 acc_val: 0.4620 time: 6.1246s 0 0\n",
            "Epoch: 0425 loss_train: 1.3926 acc_train: 0.5280 loss_val: 2.1833 acc_val: 0.4680 time: 6.1390s 0 0\n",
            "Epoch: 0426 loss_train: 1.3557 acc_train: 0.5360 loss_val: 2.2138 acc_val: 0.4700 time: 6.1568s 0 0\n",
            "Epoch: 0427 loss_train: 1.3369 acc_train: 0.5620 loss_val: 2.2640 acc_val: 0.4700 time: 6.1709s 0 0\n",
            "Epoch: 0428 loss_train: 1.3926 acc_train: 0.5120 loss_val: 2.3106 acc_val: 0.4700 time: 6.1877s 0 0\n",
            "Epoch: 0429 loss_train: 1.3563 acc_train: 0.5420 loss_val: 2.3732 acc_val: 0.4640 time: 6.2028s 0 0\n",
            "Epoch: 0430 loss_train: 1.3298 acc_train: 0.5600 loss_val: 2.4315 acc_val: 0.4720 time: 6.2204s 0 0\n",
            "Epoch: 0431 loss_train: 1.3560 acc_train: 0.5480 loss_val: 2.4831 acc_val: 0.4780 time: 6.2361s 0 0\n",
            "Epoch: 0432 loss_train: 1.3851 acc_train: 0.5420 loss_val: 2.4926 acc_val: 0.4840 time: 6.2507s 0 0\n",
            "Epoch: 0433 loss_train: 1.3441 acc_train: 0.5540 loss_val: 2.4858 acc_val: 0.4840 time: 6.2664s 0 0\n",
            "Epoch: 0434 loss_train: 1.3112 acc_train: 0.5640 loss_val: 2.4841 acc_val: 0.4800 time: 6.2788s 0 0\n",
            "Epoch: 0435 loss_train: 1.3510 acc_train: 0.5400 loss_val: 2.4796 acc_val: 0.4860 time: 6.2911s 0 0\n",
            "Epoch: 0436 loss_train: 1.3643 acc_train: 0.5480 loss_val: 2.4690 acc_val: 0.4840 time: 6.3049s 0 0\n",
            "Epoch: 0437 loss_train: 1.3128 acc_train: 0.5640 loss_val: 2.4584 acc_val: 0.4840 time: 6.3186s 0 0\n",
            "Epoch: 0438 loss_train: 1.3173 acc_train: 0.5500 loss_val: 2.4733 acc_val: 0.4880 time: 6.3327s 0 0\n",
            "Epoch: 0439 loss_train: 1.3380 acc_train: 0.5500 loss_val: 2.4844 acc_val: 0.4860 time: 6.3466s 0 0\n",
            "Epoch: 0440 loss_train: 1.3309 acc_train: 0.5440 loss_val: 2.4736 acc_val: 0.4840 time: 6.3625s 0 0\n",
            "Epoch: 0441 loss_train: 1.3165 acc_train: 0.5580 loss_val: 2.4246 acc_val: 0.4860 time: 6.3816s 0 0\n",
            "Epoch: 0442 loss_train: 1.3828 acc_train: 0.5240 loss_val: 2.3630 acc_val: 0.4720 time: 6.3966s 0 0\n",
            "Epoch: 0443 loss_train: 1.3445 acc_train: 0.5280 loss_val: 2.3056 acc_val: 0.4680 time: 6.4121s 0 0\n",
            "Epoch: 0444 loss_train: 1.3376 acc_train: 0.5340 loss_val: 2.2615 acc_val: 0.4700 time: 6.4271s 0 0\n",
            "Epoch: 0445 loss_train: 1.3472 acc_train: 0.5320 loss_val: 2.2730 acc_val: 0.4780 time: 6.4407s 0 0\n",
            "Epoch: 0446 loss_train: 1.3147 acc_train: 0.5280 loss_val: 2.2835 acc_val: 0.4720 time: 6.4545s 0 0\n",
            "Epoch: 0447 loss_train: 1.3448 acc_train: 0.5580 loss_val: 2.3054 acc_val: 0.4760 time: 6.4682s 0 0\n",
            "Epoch: 0448 loss_train: 1.3123 acc_train: 0.5460 loss_val: 2.3441 acc_val: 0.4800 time: 6.4808s 0 0\n",
            "Epoch: 0449 loss_train: 1.2968 acc_train: 0.5800 loss_val: 2.4025 acc_val: 0.4900 time: 6.4950s 0 0\n",
            "Epoch: 0450 loss_train: 1.3095 acc_train: 0.5360 loss_val: 2.4571 acc_val: 0.4900 time: 6.5111s 0 0\n",
            "Epoch: 0451 loss_train: 1.3122 acc_train: 0.5700 loss_val: 2.4158 acc_val: 0.4760 time: 6.5260s 0 0\n",
            "Epoch: 0452 loss_train: 1.2860 acc_train: 0.5660 loss_val: 2.3966 acc_val: 0.4640 time: 6.5398s 0 0\n",
            "Epoch: 0453 loss_train: 1.3257 acc_train: 0.5540 loss_val: 2.3934 acc_val: 0.4580 time: 6.5539s 0 0\n",
            "Epoch: 0454 loss_train: 1.3752 acc_train: 0.5440 loss_val: 2.3990 acc_val: 0.4640 time: 6.5700s 0 0\n",
            "Epoch: 0455 loss_train: 1.3551 acc_train: 0.5320 loss_val: 2.4219 acc_val: 0.4580 time: 6.5837s 0 0\n",
            "Epoch: 0456 loss_train: 1.3211 acc_train: 0.5580 loss_val: 2.4819 acc_val: 0.4680 time: 6.5957s 0 0\n",
            "Epoch: 0457 loss_train: 1.2709 acc_train: 0.5820 loss_val: 2.5417 acc_val: 0.4780 time: 6.6093s 0 0\n",
            "Epoch: 0458 loss_train: 1.2963 acc_train: 0.5440 loss_val: 2.5984 acc_val: 0.4820 time: 6.6231s 0 0\n",
            "Epoch: 0459 loss_train: 1.3411 acc_train: 0.5480 loss_val: 2.6630 acc_val: 0.4900 time: 6.6366s 0 0\n",
            "Epoch: 0460 loss_train: 1.3536 acc_train: 0.5460 loss_val: 2.6723 acc_val: 0.5000 time: 6.6498s 0 0\n",
            "Epoch: 0461 loss_train: 1.3054 acc_train: 0.5880 loss_val: 2.5920 acc_val: 0.4900 time: 6.6620s 0 0\n",
            "Epoch: 0462 loss_train: 1.2999 acc_train: 0.5480 loss_val: 2.5038 acc_val: 0.4860 time: 6.6759s 0 0\n",
            "Epoch: 0463 loss_train: 1.2761 acc_train: 0.5740 loss_val: 2.4358 acc_val: 0.4820 time: 6.6882s 0 0\n",
            "Epoch: 0464 loss_train: 1.3040 acc_train: 0.5780 loss_val: 2.4181 acc_val: 0.4820 time: 6.7005s 0 0\n",
            "Epoch: 0465 loss_train: 1.3207 acc_train: 0.5540 loss_val: 2.4228 acc_val: 0.4800 time: 6.7133s 0 0\n",
            "Epoch: 0466 loss_train: 1.2650 acc_train: 0.5840 loss_val: 2.4336 acc_val: 0.4800 time: 6.7259s 0 0\n",
            "Epoch: 0467 loss_train: 1.3201 acc_train: 0.5440 loss_val: 2.4534 acc_val: 0.4840 time: 6.7382s 0 0\n",
            "Epoch: 0468 loss_train: 1.2801 acc_train: 0.5820 loss_val: 2.4471 acc_val: 0.4860 time: 6.7503s 0 0\n",
            "Epoch: 0469 loss_train: 1.3038 acc_train: 0.5540 loss_val: 2.4879 acc_val: 0.4900 time: 6.7625s 0 0\n",
            "Epoch: 0470 loss_train: 1.3045 acc_train: 0.5600 loss_val: 2.5051 acc_val: 0.4900 time: 6.7767s 0 0\n",
            "Epoch: 0471 loss_train: 1.2914 acc_train: 0.5840 loss_val: 2.4602 acc_val: 0.4940 time: 6.7917s 0 0\n",
            "Epoch: 0472 loss_train: 1.3230 acc_train: 0.5380 loss_val: 2.3714 acc_val: 0.4940 time: 6.8061s 0 0\n",
            "Epoch: 0473 loss_train: 1.2944 acc_train: 0.5640 loss_val: 2.2769 acc_val: 0.4900 time: 6.8239s 0 0\n",
            "Epoch: 0474 loss_train: 1.2898 acc_train: 0.5520 loss_val: 2.1959 acc_val: 0.4780 time: 6.8375s 0 0\n",
            "Epoch: 0475 loss_train: 1.2967 acc_train: 0.5740 loss_val: 2.1626 acc_val: 0.4800 time: 6.8507s 0 0\n",
            "Epoch: 0476 loss_train: 1.2851 acc_train: 0.5620 loss_val: 2.1453 acc_val: 0.4800 time: 6.8636s 0 0\n",
            "Epoch: 0477 loss_train: 1.2563 acc_train: 0.5700 loss_val: 2.1456 acc_val: 0.4860 time: 6.8801s 0 0\n",
            "Epoch: 0478 loss_train: 1.2955 acc_train: 0.5640 loss_val: 2.2038 acc_val: 0.4860 time: 6.8949s 0 0\n",
            "Epoch: 0479 loss_train: 1.3056 acc_train: 0.5680 loss_val: 2.2876 acc_val: 0.4920 time: 6.9095s 0 0\n",
            "Epoch: 0480 loss_train: 1.3284 acc_train: 0.5340 loss_val: 2.3889 acc_val: 0.4940 time: 6.9227s 0 0\n",
            "Epoch: 0481 loss_train: 1.2909 acc_train: 0.5700 loss_val: 2.4743 acc_val: 0.4940 time: 6.9381s 0 0\n",
            "Epoch: 0482 loss_train: 1.2663 acc_train: 0.5700 loss_val: 2.5410 acc_val: 0.5040 time: 6.9515s 0 0\n",
            "Epoch: 0483 loss_train: 1.2945 acc_train: 0.5520 loss_val: 2.5594 acc_val: 0.5080 time: 6.9646s 0 0\n",
            "Epoch: 0484 loss_train: 1.2989 acc_train: 0.5400 loss_val: 2.5498 acc_val: 0.5000 time: 6.9815s 0 0\n",
            "Epoch: 0485 loss_train: 1.2717 acc_train: 0.5560 loss_val: 2.5216 acc_val: 0.5000 time: 6.9982s 0 0\n",
            "Epoch: 0486 loss_train: 1.2819 acc_train: 0.5900 loss_val: 2.4761 acc_val: 0.4980 time: 7.0119s 0 0\n",
            "Epoch: 0487 loss_train: 1.3292 acc_train: 0.5520 loss_val: 2.4090 acc_val: 0.4920 time: 7.0264s 0 0\n",
            "Epoch: 0488 loss_train: 1.2675 acc_train: 0.5720 loss_val: 2.3740 acc_val: 0.4920 time: 7.0455s 0 0\n",
            "Epoch: 0489 loss_train: 1.2579 acc_train: 0.5840 loss_val: 2.3623 acc_val: 0.4940 time: 7.0591s 0 0\n",
            "Epoch: 0490 loss_train: 1.3017 acc_train: 0.5580 loss_val: 2.4000 acc_val: 0.5000 time: 7.0739s 0 0\n",
            "Epoch: 0491 loss_train: 1.3180 acc_train: 0.5580 loss_val: 2.4331 acc_val: 0.4920 time: 7.0880s 0 0\n",
            "Epoch: 0492 loss_train: 1.2502 acc_train: 0.5700 loss_val: 2.4449 acc_val: 0.4920 time: 7.1070s 0 0\n",
            "Epoch: 0493 loss_train: 1.2692 acc_train: 0.5600 loss_val: 2.4360 acc_val: 0.4940 time: 7.1203s 0 0\n",
            "Epoch: 0494 loss_train: 1.2590 acc_train: 0.5820 loss_val: 2.4653 acc_val: 0.4940 time: 7.1330s 0 0\n",
            "Epoch: 0495 loss_train: 1.3010 acc_train: 0.5400 loss_val: 2.4815 acc_val: 0.5020 time: 7.1468s 0 0\n",
            "Epoch: 0496 loss_train: 1.3057 acc_train: 0.5540 loss_val: 2.5183 acc_val: 0.5020 time: 7.1602s 0 0\n",
            "Epoch: 0497 loss_train: 1.2699 acc_train: 0.5700 loss_val: 2.5565 acc_val: 0.5060 time: 7.1741s 0 0\n",
            "Epoch: 0498 loss_train: 1.2827 acc_train: 0.5660 loss_val: 2.5809 acc_val: 0.5060 time: 7.1866s 0 0\n",
            "Epoch: 0499 loss_train: 1.2853 acc_train: 0.5620 loss_val: 2.5339 acc_val: 0.5060 time: 7.2044s 0 0\n",
            "Epoch: 0500 loss_train: 1.2610 acc_train: 0.5740 loss_val: 2.4872 acc_val: 0.5060 time: 7.2178s 0 0\n",
            "Epoch: 0501 loss_train: 1.2897 acc_train: 0.5620 loss_val: 2.4169 acc_val: 0.5060 time: 7.2314s 0 0\n",
            "Epoch: 0502 loss_train: 1.2671 acc_train: 0.5660 loss_val: 2.3723 acc_val: 0.5000 time: 7.2448s 0 0\n",
            "Epoch: 0503 loss_train: 1.2177 acc_train: 0.5900 loss_val: 2.3550 acc_val: 0.4960 time: 7.2585s 0 0\n",
            "Epoch: 0504 loss_train: 1.2613 acc_train: 0.5660 loss_val: 2.3462 acc_val: 0.4960 time: 7.2720s 0 0\n",
            "Epoch: 0505 loss_train: 1.2730 acc_train: 0.5680 loss_val: 2.3408 acc_val: 0.4980 time: 7.2855s 0 0\n",
            "Epoch: 0506 loss_train: 1.2467 acc_train: 0.5800 loss_val: 2.3285 acc_val: 0.4920 time: 7.2998s 0 0\n",
            "Epoch: 0507 loss_train: 1.2678 acc_train: 0.5540 loss_val: 2.3289 acc_val: 0.4960 time: 7.3133s 0 0\n",
            "Epoch: 0508 loss_train: 1.2692 acc_train: 0.5660 loss_val: 2.3320 acc_val: 0.4980 time: 7.3262s 0 0\n",
            "Epoch: 0509 loss_train: 1.2925 acc_train: 0.5660 loss_val: 2.1898 acc_val: 0.4940 time: 7.3395s 0 0\n",
            "Epoch: 0510 loss_train: 1.2592 acc_train: 0.5800 loss_val: 2.1626 acc_val: 0.4800 time: 7.3530s 0 0\n",
            "Epoch: 0511 loss_train: 1.2258 acc_train: 0.5660 loss_val: 2.1783 acc_val: 0.4760 time: 7.3667s 0 0\n",
            "Epoch: 0512 loss_train: 1.2892 acc_train: 0.5480 loss_val: 2.2560 acc_val: 0.4760 time: 7.3813s 0 0\n",
            "Epoch: 0513 loss_train: 1.2747 acc_train: 0.5800 loss_val: 2.3769 acc_val: 0.4840 time: 7.3946s 0 0\n",
            "Epoch: 0514 loss_train: 1.2560 acc_train: 0.5800 loss_val: 2.4737 acc_val: 0.4880 time: 7.4121s 0 0\n",
            "Epoch: 0515 loss_train: 1.2190 acc_train: 0.5820 loss_val: 2.5182 acc_val: 0.4920 time: 7.4272s 0 0\n",
            "Epoch: 0516 loss_train: 1.3147 acc_train: 0.5620 loss_val: 2.4753 acc_val: 0.5080 time: 7.4425s 0 0\n",
            "Epoch: 0517 loss_train: 1.2183 acc_train: 0.6140 loss_val: 2.3744 acc_val: 0.5080 time: 7.4586s 0 0\n",
            "Epoch: 0518 loss_train: 1.2819 acc_train: 0.5460 loss_val: 2.3396 acc_val: 0.5020 time: 7.4725s 0 0\n",
            "Epoch: 0519 loss_train: 1.3007 acc_train: 0.5520 loss_val: 2.3229 acc_val: 0.5000 time: 7.4881s 0 0\n",
            "Epoch: 0520 loss_train: 1.2277 acc_train: 0.5820 loss_val: 2.3443 acc_val: 0.4960 time: 7.5010s 0 0\n",
            "Epoch: 0521 loss_train: 1.2758 acc_train: 0.5660 loss_val: 2.3377 acc_val: 0.5040 time: 7.5194s 0 0\n",
            "Epoch: 0522 loss_train: 1.2360 acc_train: 0.5940 loss_val: 2.3029 acc_val: 0.5080 time: 7.5331s 0 0\n",
            "Epoch: 0523 loss_train: 1.2514 acc_train: 0.5860 loss_val: 2.2948 acc_val: 0.5160 time: 7.5475s 0 0\n",
            "Epoch: 0524 loss_train: 1.2476 acc_train: 0.5660 loss_val: 2.2107 acc_val: 0.5160 time: 7.5614s 0 0\n",
            "Epoch: 0525 loss_train: 1.2453 acc_train: 0.5940 loss_val: 2.1944 acc_val: 0.5200 time: 7.5783s 0 0\n",
            "Epoch: 0526 loss_train: 1.2408 acc_train: 0.5600 loss_val: 2.2032 acc_val: 0.5180 time: 7.5921s 0 0\n",
            "Epoch: 0527 loss_train: 1.2295 acc_train: 0.5860 loss_val: 2.2200 acc_val: 0.5020 time: 7.6053s 0 0\n",
            "Epoch: 0528 loss_train: 1.2523 acc_train: 0.5880 loss_val: 2.2476 acc_val: 0.4940 time: 7.6219s 0 0\n",
            "Epoch: 0529 loss_train: 1.2372 acc_train: 0.5960 loss_val: 2.2813 acc_val: 0.4940 time: 7.6362s 0 0\n",
            "Epoch: 0530 loss_train: 1.2483 acc_train: 0.5820 loss_val: 2.3561 acc_val: 0.5040 time: 7.6507s 0 0\n",
            "Epoch: 0531 loss_train: 1.2482 acc_train: 0.5920 loss_val: 2.3883 acc_val: 0.5080 time: 7.6646s 0 0\n",
            "Epoch: 0532 loss_train: 1.2534 acc_train: 0.5760 loss_val: 2.4014 acc_val: 0.5060 time: 7.6800s 0 0\n",
            "Epoch: 0533 loss_train: 1.2585 acc_train: 0.5900 loss_val: 2.3792 acc_val: 0.5040 time: 7.6933s 0 0\n",
            "Epoch: 0534 loss_train: 1.2613 acc_train: 0.5760 loss_val: 2.3787 acc_val: 0.5080 time: 7.7054s 0 0\n",
            "Epoch: 0535 loss_train: 1.2195 acc_train: 0.5920 loss_val: 2.3675 acc_val: 0.5060 time: 7.7177s 0 0\n",
            "Epoch: 0536 loss_train: 1.2011 acc_train: 0.6000 loss_val: 2.3741 acc_val: 0.5040 time: 7.7312s 0 0\n",
            "Epoch: 0537 loss_train: 1.2356 acc_train: 0.5680 loss_val: 2.3473 acc_val: 0.5040 time: 7.7435s 0 0\n",
            "Epoch: 0538 loss_train: 1.2166 acc_train: 0.6020 loss_val: 2.3987 acc_val: 0.5080 time: 7.7560s 0 0\n",
            "Epoch: 0539 loss_train: 1.2487 acc_train: 0.5700 loss_val: 2.4824 acc_val: 0.5060 time: 7.7700s 0 0\n",
            "Epoch: 0540 loss_train: 1.2374 acc_train: 0.5880 loss_val: 2.5493 acc_val: 0.5040 time: 7.7827s 0 0\n",
            "Epoch: 0541 loss_train: 1.2254 acc_train: 0.5800 loss_val: 2.5632 acc_val: 0.4980 time: 7.7951s 0 0\n",
            "Epoch: 0542 loss_train: 1.2346 acc_train: 0.5800 loss_val: 2.4256 acc_val: 0.4940 time: 7.8089s 0 0\n",
            "Epoch: 0543 loss_train: 1.2268 acc_train: 0.5900 loss_val: 2.3382 acc_val: 0.5000 time: 7.8228s 0 0\n",
            "Epoch: 0544 loss_train: 1.2369 acc_train: 0.5940 loss_val: 2.3137 acc_val: 0.5000 time: 7.8397s 0 0\n",
            "Epoch: 0545 loss_train: 1.2271 acc_train: 0.5800 loss_val: 2.3245 acc_val: 0.4960 time: 7.8532s 0 0\n",
            "Epoch: 0546 loss_train: 1.2649 acc_train: 0.5760 loss_val: 2.3633 acc_val: 0.5000 time: 7.8667s 0 0\n",
            "Epoch: 0547 loss_train: 1.1943 acc_train: 0.5940 loss_val: 2.4245 acc_val: 0.5080 time: 7.8816s 0 0\n",
            "Epoch: 0548 loss_train: 1.2449 acc_train: 0.5700 loss_val: 2.4811 acc_val: 0.5120 time: 7.8950s 0 0\n",
            "Epoch: 0549 loss_train: 1.2160 acc_train: 0.5980 loss_val: 2.5699 acc_val: 0.5120 time: 7.9106s 0 0\n",
            "Epoch: 0550 loss_train: 1.2346 acc_train: 0.6020 loss_val: 2.5073 acc_val: 0.5100 time: 7.9246s 0 0\n",
            "Epoch: 0551 loss_train: 1.2504 acc_train: 0.5720 loss_val: 2.4160 acc_val: 0.5000 time: 7.9402s 0 0\n",
            "Epoch: 0552 loss_train: 1.2597 acc_train: 0.5860 loss_val: 2.3454 acc_val: 0.4980 time: 7.9553s 0 0\n",
            "Epoch: 0553 loss_train: 1.2365 acc_train: 0.5780 loss_val: 2.2935 acc_val: 0.4940 time: 7.9702s 0 0\n",
            "Epoch: 0554 loss_train: 1.2345 acc_train: 0.5980 loss_val: 2.2930 acc_val: 0.4940 time: 7.9847s 0 0\n",
            "Epoch: 0555 loss_train: 1.2279 acc_train: 0.5840 loss_val: 2.2729 acc_val: 0.4940 time: 7.9995s 0 0\n",
            "Epoch: 0556 loss_train: 1.2338 acc_train: 0.5920 loss_val: 2.2625 acc_val: 0.5040 time: 8.0141s 0 0\n",
            "Epoch: 0557 loss_train: 1.2086 acc_train: 0.5880 loss_val: 2.2919 acc_val: 0.5040 time: 8.0283s 0 0\n",
            "Epoch: 0558 loss_train: 1.2093 acc_train: 0.5940 loss_val: 2.3667 acc_val: 0.5020 time: 8.0499s 0 0\n",
            "Epoch: 0559 loss_train: 1.2516 acc_train: 0.5740 loss_val: 2.3818 acc_val: 0.5120 time: 8.0661s 0 0\n",
            "Epoch: 0560 loss_train: 1.2261 acc_train: 0.5900 loss_val: 2.3954 acc_val: 0.5120 time: 8.0814s 0 0\n",
            "Epoch: 0561 loss_train: 1.2162 acc_train: 0.5900 loss_val: 2.4443 acc_val: 0.5120 time: 8.0957s 0 0\n",
            "Epoch: 0562 loss_train: 1.2594 acc_train: 0.5600 loss_val: 2.5136 acc_val: 0.5040 time: 8.1112s 0 0\n",
            "Epoch: 0563 loss_train: 1.2383 acc_train: 0.5800 loss_val: 2.2327 acc_val: 0.4920 time: 8.1268s 0 0\n",
            "Epoch: 0564 loss_train: 1.2616 acc_train: 0.5640 loss_val: 2.1790 acc_val: 0.4940 time: 8.1414s 0 0\n",
            "Epoch: 0565 loss_train: 1.2198 acc_train: 0.5780 loss_val: 2.1882 acc_val: 0.4840 time: 8.1570s 0 0\n",
            "Epoch: 0566 loss_train: 1.2357 acc_train: 0.5860 loss_val: 2.1795 acc_val: 0.4860 time: 8.1766s 0 0\n",
            "Epoch: 0567 loss_train: 1.2470 acc_train: 0.5840 loss_val: 2.1460 acc_val: 0.4940 time: 8.1920s 0 0\n",
            "Epoch: 0568 loss_train: 1.2317 acc_train: 0.5740 loss_val: 2.1566 acc_val: 0.5020 time: 8.2061s 0 0\n",
            "Epoch: 0569 loss_train: 1.2026 acc_train: 0.5860 loss_val: 2.1559 acc_val: 0.5000 time: 8.2207s 0 0\n",
            "Epoch: 0570 loss_train: 1.2225 acc_train: 0.5940 loss_val: 2.1304 acc_val: 0.4980 time: 8.2342s 0 0\n",
            "Epoch: 0571 loss_train: 1.2204 acc_train: 0.5700 loss_val: 2.1311 acc_val: 0.5020 time: 8.2476s 0 0\n",
            "Epoch: 0572 loss_train: 1.2824 acc_train: 0.5540 loss_val: 2.1761 acc_val: 0.5140 time: 8.2656s 0 0\n",
            "Epoch: 0573 loss_train: 1.2270 acc_train: 0.5900 loss_val: 2.2574 acc_val: 0.5140 time: 8.2817s 0 0\n",
            "Epoch: 0574 loss_train: 1.1992 acc_train: 0.5940 loss_val: 2.3863 acc_val: 0.5120 time: 8.2945s 0 0\n",
            "Epoch: 0575 loss_train: 1.2035 acc_train: 0.5900 loss_val: 2.4997 acc_val: 0.5160 time: 8.3096s 0 0\n",
            "Epoch: 0576 loss_train: 1.2403 acc_train: 0.5880 loss_val: 2.4864 acc_val: 0.5240 time: 8.3238s 0 0\n",
            "Epoch: 0577 loss_train: 1.2288 acc_train: 0.5720 loss_val: 2.3349 acc_val: 0.5200 time: 8.3368s 0 0\n",
            "Epoch: 0578 loss_train: 1.2254 acc_train: 0.5740 loss_val: 2.2050 acc_val: 0.5140 time: 8.3519s 0 0\n",
            "Epoch: 0579 loss_train: 1.2156 acc_train: 0.5780 loss_val: 2.0803 acc_val: 0.5080 time: 8.3660s 0 0\n",
            "Epoch: 0580 loss_train: 1.2211 acc_train: 0.5800 loss_val: 2.0834 acc_val: 0.5000 time: 8.3805s 0 0\n",
            "Epoch: 0581 loss_train: 1.2031 acc_train: 0.5880 loss_val: 2.2082 acc_val: 0.5020 time: 8.3940s 0 0\n",
            "Epoch: 0582 loss_train: 1.2551 acc_train: 0.5540 loss_val: 2.2962 acc_val: 0.5000 time: 8.4084s 0 0\n",
            "Epoch: 0583 loss_train: 1.2153 acc_train: 0.5740 loss_val: 2.3486 acc_val: 0.4980 time: 8.4216s 0 0\n",
            "Epoch: 0584 loss_train: 1.2572 acc_train: 0.5720 loss_val: 2.1337 acc_val: 0.5020 time: 8.4359s 0 0\n",
            "Epoch: 0585 loss_train: 1.2057 acc_train: 0.5980 loss_val: 2.1088 acc_val: 0.5060 time: 8.4488s 0 0\n",
            "Epoch: 0586 loss_train: 1.2335 acc_train: 0.5760 loss_val: 2.1186 acc_val: 0.5100 time: 8.4623s 0 0\n",
            "Epoch: 0587 loss_train: 1.2377 acc_train: 0.5800 loss_val: 2.1380 acc_val: 0.5180 time: 8.4794s 0 0\n",
            "Epoch: 0588 loss_train: 1.1903 acc_train: 0.6040 loss_val: 2.2117 acc_val: 0.5200 time: 8.4961s 0 0\n",
            "Epoch: 0589 loss_train: 1.1991 acc_train: 0.5760 loss_val: 2.2714 acc_val: 0.5180 time: 8.5091s 0 0\n",
            "Epoch: 0590 loss_train: 1.1885 acc_train: 0.5900 loss_val: 2.3265 acc_val: 0.5160 time: 8.5227s 0 0\n",
            "Epoch: 0591 loss_train: 1.2038 acc_train: 0.5920 loss_val: 2.3209 acc_val: 0.5140 time: 8.5360s 0 0\n",
            "Epoch: 0592 loss_train: 1.1921 acc_train: 0.6020 loss_val: 2.2881 acc_val: 0.5120 time: 8.5490s 0 0\n",
            "Epoch: 0593 loss_train: 1.2335 acc_train: 0.5720 loss_val: 2.2729 acc_val: 0.5220 time: 8.5637s 0 0\n",
            "Epoch: 0594 loss_train: 1.2267 acc_train: 0.5800 loss_val: 2.2586 acc_val: 0.5240 time: 8.5774s 0 0\n",
            "Epoch: 0595 loss_train: 1.2242 acc_train: 0.5980 loss_val: 2.2137 acc_val: 0.5180 time: 8.5902s 0 0\n",
            "Epoch: 0596 loss_train: 1.2179 acc_train: 0.5900 loss_val: 2.1777 acc_val: 0.5160 time: 8.6033s 0 0\n",
            "Epoch: 0597 loss_train: 1.2149 acc_train: 0.5900 loss_val: 2.1698 acc_val: 0.5080 time: 8.6166s 0 0\n",
            "Epoch: 0598 loss_train: 1.1908 acc_train: 0.6040 loss_val: 2.1761 acc_val: 0.5080 time: 8.6300s 0 0\n",
            "Epoch: 0599 loss_train: 1.1922 acc_train: 0.6180 loss_val: 2.1810 acc_val: 0.5020 time: 8.6422s 0 0\n",
            "Epoch: 0600 loss_train: 1.2072 acc_train: 0.5920 loss_val: 2.2347 acc_val: 0.5080 time: 8.6539s 0 0\n",
            "Epoch: 0601 loss_train: 1.2324 acc_train: 0.6000 loss_val: 2.3029 acc_val: 0.5180 time: 8.6666s 0 0\n",
            "Epoch: 0602 loss_train: 1.1890 acc_train: 0.6040 loss_val: 2.3663 acc_val: 0.5180 time: 8.6841s 0 0\n",
            "Epoch: 0603 loss_train: 1.1916 acc_train: 0.5960 loss_val: 2.4201 acc_val: 0.5200 time: 8.7001s 0 0\n",
            "Epoch: 0604 loss_train: 1.1925 acc_train: 0.6080 loss_val: 2.4762 acc_val: 0.5220 time: 8.7175s 0 0\n",
            "Epoch: 0605 loss_train: 1.1848 acc_train: 0.5980 loss_val: 2.4366 acc_val: 0.5220 time: 8.7309s 0 0\n",
            "Epoch: 0606 loss_train: 1.2209 acc_train: 0.5940 loss_val: 2.3849 acc_val: 0.5180 time: 8.7445s 0 0\n",
            "Epoch: 0607 loss_train: 1.2140 acc_train: 0.5820 loss_val: 2.3282 acc_val: 0.5200 time: 8.7566s 0 0\n",
            "Epoch: 0608 loss_train: 1.1749 acc_train: 0.6040 loss_val: 2.3029 acc_val: 0.5280 time: 8.7696s 0 0\n",
            "Epoch: 0609 loss_train: 1.1846 acc_train: 0.5940 loss_val: 2.3018 acc_val: 0.5280 time: 8.7866s 0 0\n",
            "Epoch: 0610 loss_train: 1.1919 acc_train: 0.5960 loss_val: 2.2878 acc_val: 0.5220 time: 8.8018s 0 0\n",
            "Epoch: 0611 loss_train: 1.1883 acc_train: 0.6000 loss_val: 2.3123 acc_val: 0.5280 time: 8.8160s 0 0\n",
            "Epoch: 0612 loss_train: 1.2036 acc_train: 0.5920 loss_val: 2.3231 acc_val: 0.5340 time: 8.8313s 0 0\n",
            "Epoch: 0613 loss_train: 1.1694 acc_train: 0.6060 loss_val: 2.3197 acc_val: 0.5320 time: 8.8470s 0 0\n",
            "Epoch: 0614 loss_train: 1.2042 acc_train: 0.5860 loss_val: 2.3327 acc_val: 0.5340 time: 8.8617s 0 0\n",
            "Epoch: 0615 loss_train: 1.2092 acc_train: 0.5980 loss_val: 2.3488 acc_val: 0.5360 time: 8.8771s 0 0\n",
            "Epoch: 0616 loss_train: 1.2102 acc_train: 0.6200 loss_val: 2.3380 acc_val: 0.5280 time: 8.8921s 0 0\n",
            "Epoch: 0617 loss_train: 1.1827 acc_train: 0.6140 loss_val: 2.3266 acc_val: 0.5220 time: 8.9091s 0 0\n",
            "Epoch: 0618 loss_train: 1.1723 acc_train: 0.6120 loss_val: 2.3796 acc_val: 0.5280 time: 8.9259s 0 0\n",
            "Epoch: 0619 loss_train: 1.2041 acc_train: 0.6000 loss_val: 2.3792 acc_val: 0.5240 time: 8.9414s 0 0\n",
            "Epoch: 0620 loss_train: 1.1945 acc_train: 0.5980 loss_val: 2.3915 acc_val: 0.5220 time: 8.9587s 0 0\n",
            "Epoch: 0621 loss_train: 1.1970 acc_train: 0.5840 loss_val: 2.4346 acc_val: 0.5240 time: 8.9724s 0 0\n",
            "Epoch: 0622 loss_train: 1.1853 acc_train: 0.6040 loss_val: 2.4058 acc_val: 0.5300 time: 8.9875s 0 0\n",
            "Epoch: 0623 loss_train: 1.1526 acc_train: 0.6240 loss_val: 2.3700 acc_val: 0.5300 time: 9.0013s 0 0\n",
            "Epoch: 0624 loss_train: 1.1964 acc_train: 0.6180 loss_val: 2.3462 acc_val: 0.5300 time: 9.0152s 0 0\n",
            "Epoch: 0625 loss_train: 1.1688 acc_train: 0.6300 loss_val: 2.3619 acc_val: 0.5260 time: 9.0297s 0 0\n",
            "Epoch: 0626 loss_train: 1.1774 acc_train: 0.5960 loss_val: 2.3789 acc_val: 0.5300 time: 9.0443s 0 0\n",
            "Epoch: 0627 loss_train: 1.2002 acc_train: 0.5800 loss_val: 2.3698 acc_val: 0.5320 time: 9.0620s 0 0\n",
            "Epoch: 0628 loss_train: 1.2269 acc_train: 0.5740 loss_val: 2.2692 acc_val: 0.5200 time: 9.0763s 0 0\n",
            "Epoch: 0629 loss_train: 1.1474 acc_train: 0.6160 loss_val: 2.2610 acc_val: 0.5220 time: 9.0905s 0 0\n",
            "Epoch: 0630 loss_train: 1.1794 acc_train: 0.6020 loss_val: 2.2220 acc_val: 0.5140 time: 9.1047s 0 0\n",
            "Epoch: 0631 loss_train: 1.1937 acc_train: 0.5980 loss_val: 2.1859 acc_val: 0.5000 time: 9.1197s 0 0\n",
            "Epoch: 0632 loss_train: 1.1880 acc_train: 0.5940 loss_val: 2.1567 acc_val: 0.5080 time: 9.1335s 0 0\n",
            "Epoch: 0633 loss_train: 1.1857 acc_train: 0.6040 loss_val: 2.1954 acc_val: 0.5280 time: 9.1481s 0 0\n",
            "Epoch: 0634 loss_train: 1.1884 acc_train: 0.5980 loss_val: 2.2754 acc_val: 0.5200 time: 9.1615s 0 0\n",
            "Epoch: 0635 loss_train: 1.1912 acc_train: 0.5960 loss_val: 2.3870 acc_val: 0.5240 time: 9.1749s 0 0\n",
            "Epoch: 0636 loss_train: 1.1563 acc_train: 0.6020 loss_val: 2.4430 acc_val: 0.5200 time: 9.1880s 0 0\n",
            "Epoch: 0637 loss_train: 1.1700 acc_train: 0.6280 loss_val: 2.4426 acc_val: 0.5240 time: 9.2013s 0 0\n",
            "Epoch: 0638 loss_train: 1.1664 acc_train: 0.6020 loss_val: 2.4466 acc_val: 0.5280 time: 9.2162s 0 0\n",
            "Epoch: 0639 loss_train: 1.1609 acc_train: 0.6040 loss_val: 2.4690 acc_val: 0.5280 time: 9.2310s 0 0\n",
            "Epoch: 0640 loss_train: 1.1682 acc_train: 0.6020 loss_val: 2.4796 acc_val: 0.5300 time: 9.2455s 0 0\n",
            "Epoch: 0641 loss_train: 1.1741 acc_train: 0.5960 loss_val: 2.4873 acc_val: 0.5320 time: 9.2598s 0 0\n",
            "Epoch: 0642 loss_train: 1.1916 acc_train: 0.6040 loss_val: 2.4569 acc_val: 0.5300 time: 9.2742s 0 0\n",
            "Epoch: 0643 loss_train: 1.1617 acc_train: 0.6080 loss_val: 2.4585 acc_val: 0.5300 time: 9.2886s 0 0\n",
            "Epoch: 0644 loss_train: 1.1538 acc_train: 0.6280 loss_val: 2.4513 acc_val: 0.5280 time: 9.3021s 0 0\n",
            "Epoch: 0645 loss_train: 1.1672 acc_train: 0.6000 loss_val: 2.4178 acc_val: 0.5300 time: 9.3191s 0 0\n",
            "Epoch: 0646 loss_train: 1.1645 acc_train: 0.6120 loss_val: 2.3831 acc_val: 0.5300 time: 9.3335s 0 0\n",
            "Epoch: 0647 loss_train: 1.1925 acc_train: 0.5800 loss_val: 2.3065 acc_val: 0.5300 time: 9.3478s 0 0\n",
            "Epoch: 0648 loss_train: 1.1681 acc_train: 0.6140 loss_val: 2.2379 acc_val: 0.5280 time: 9.3617s 0 0\n",
            "Epoch: 0649 loss_train: 1.1068 acc_train: 0.6260 loss_val: 2.2078 acc_val: 0.5300 time: 9.3756s 0 0\n",
            "Epoch: 0650 loss_train: 1.1762 acc_train: 0.6200 loss_val: 2.2086 acc_val: 0.5300 time: 9.3918s 0 0\n",
            "Epoch: 0651 loss_train: 1.1524 acc_train: 0.6200 loss_val: 2.2120 acc_val: 0.5360 time: 9.4052s 0 0\n",
            "Epoch: 0652 loss_train: 1.1566 acc_train: 0.6140 loss_val: 2.2129 acc_val: 0.5400 time: 9.4192s 0 0\n",
            "Epoch: 0653 loss_train: 1.1564 acc_train: 0.6060 loss_val: 2.2580 acc_val: 0.5180 time: 9.4335s 0 0\n",
            "Epoch: 0654 loss_train: 1.1887 acc_train: 0.5920 loss_val: 2.3057 acc_val: 0.5120 time: 9.4481s 0 0\n",
            "Epoch: 0655 loss_train: 1.1626 acc_train: 0.6020 loss_val: 2.3281 acc_val: 0.5100 time: 9.4616s 0 0\n",
            "Epoch: 0656 loss_train: 1.1799 acc_train: 0.6020 loss_val: 2.3471 acc_val: 0.5060 time: 9.4777s 0 0\n",
            "Epoch: 0657 loss_train: 1.1585 acc_train: 0.6060 loss_val: 2.3796 acc_val: 0.5080 time: 9.4903s 0 0\n",
            "Epoch: 0658 loss_train: 1.1644 acc_train: 0.6140 loss_val: 2.3890 acc_val: 0.5240 time: 9.5039s 0 0\n",
            "Epoch: 0659 loss_train: 1.1870 acc_train: 0.5960 loss_val: 2.3965 acc_val: 0.5300 time: 9.5189s 0 0\n",
            "Epoch: 0660 loss_train: 1.1928 acc_train: 0.5880 loss_val: 2.3850 acc_val: 0.5400 time: 9.5350s 0 0\n",
            "Epoch: 0661 loss_train: 1.1487 acc_train: 0.6340 loss_val: 2.3951 acc_val: 0.5300 time: 9.5488s 0 0\n",
            "Epoch: 0662 loss_train: 1.1676 acc_train: 0.5980 loss_val: 2.3749 acc_val: 0.5340 time: 9.5634s 0 0\n",
            "Epoch: 0663 loss_train: 1.1775 acc_train: 0.6020 loss_val: 2.3666 acc_val: 0.5360 time: 9.5789s 0 0\n",
            "Epoch: 0664 loss_train: 1.1610 acc_train: 0.6220 loss_val: 2.3443 acc_val: 0.5380 time: 9.5950s 0 0\n",
            "Epoch: 0665 loss_train: 1.2002 acc_train: 0.5980 loss_val: 2.3861 acc_val: 0.5380 time: 9.6088s 0 0\n",
            "Epoch: 0666 loss_train: 1.1556 acc_train: 0.6160 loss_val: 2.4583 acc_val: 0.5400 time: 9.6229s 0 0\n",
            "Epoch: 0667 loss_train: 1.1237 acc_train: 0.6340 loss_val: 2.5037 acc_val: 0.5360 time: 9.6388s 0 0\n",
            "Epoch: 0668 loss_train: 1.1547 acc_train: 0.6180 loss_val: 2.5205 acc_val: 0.5400 time: 9.6535s 0 0\n",
            "Epoch: 0669 loss_train: 1.1658 acc_train: 0.6080 loss_val: 2.5071 acc_val: 0.5340 time: 9.6682s 0 0\n",
            "Epoch: 0670 loss_train: 1.1788 acc_train: 0.6000 loss_val: 2.4658 acc_val: 0.5320 time: 9.6812s 0 0\n",
            "Epoch: 0671 loss_train: 1.1704 acc_train: 0.6140 loss_val: 2.4373 acc_val: 0.5320 time: 9.6973s 0 0\n",
            "Epoch: 0672 loss_train: 1.1483 acc_train: 0.6140 loss_val: 2.4295 acc_val: 0.5280 time: 9.7133s 0 0\n",
            "Epoch: 0673 loss_train: 1.1529 acc_train: 0.6160 loss_val: 2.3779 acc_val: 0.5220 time: 9.7271s 0 0\n",
            "Epoch: 0674 loss_train: 1.1442 acc_train: 0.6320 loss_val: 2.3397 acc_val: 0.5180 time: 9.7445s 0 0\n",
            "Epoch: 0675 loss_train: 1.1391 acc_train: 0.6320 loss_val: 2.2316 acc_val: 0.5280 time: 9.7583s 0 0\n",
            "Epoch: 0676 loss_train: 1.1741 acc_train: 0.6080 loss_val: 2.2313 acc_val: 0.5300 time: 9.7740s 0 0\n",
            "Epoch: 0677 loss_train: 1.1856 acc_train: 0.6040 loss_val: 2.2012 acc_val: 0.5320 time: 9.7885s 0 0\n",
            "Epoch: 0678 loss_train: 1.1715 acc_train: 0.5900 loss_val: 2.1955 acc_val: 0.5320 time: 9.8061s 0 0\n",
            "Epoch: 0679 loss_train: 1.1648 acc_train: 0.6120 loss_val: 2.1894 acc_val: 0.5360 time: 9.8198s 0 0\n",
            "Epoch: 0680 loss_train: 1.1557 acc_train: 0.6160 loss_val: 2.1922 acc_val: 0.5420 time: 9.8345s 0 0\n",
            "Epoch: 0681 loss_train: 1.1771 acc_train: 0.6000 loss_val: 2.2219 acc_val: 0.5440 time: 9.8476s 0 0\n",
            "Epoch: 0682 loss_train: 1.1683 acc_train: 0.6400 loss_val: 2.2845 acc_val: 0.5320 time: 9.8612s 0 0\n",
            "Epoch: 0683 loss_train: 1.1651 acc_train: 0.6380 loss_val: 2.4357 acc_val: 0.5340 time: 9.8744s 0 0\n",
            "Epoch: 0684 loss_train: 1.1870 acc_train: 0.6200 loss_val: 2.4685 acc_val: 0.5380 time: 9.8873s 0 0\n",
            "Epoch: 0685 loss_train: 1.1794 acc_train: 0.6080 loss_val: 2.4802 acc_val: 0.5440 time: 9.9005s 0 0\n",
            "Epoch: 0686 loss_train: 1.1584 acc_train: 0.6160 loss_val: 2.4716 acc_val: 0.5500 time: 9.9159s 0 0\n",
            "Epoch: 0687 loss_train: 1.1256 acc_train: 0.6360 loss_val: 2.4356 acc_val: 0.5460 time: 9.9294s 0 0\n",
            "Epoch: 0688 loss_train: 1.1541 acc_train: 0.6100 loss_val: 2.3265 acc_val: 0.5340 time: 9.9430s 0 0\n",
            "Epoch: 0689 loss_train: 1.1206 acc_train: 0.6600 loss_val: 2.2768 acc_val: 0.5360 time: 9.9597s 0 0\n",
            "Epoch: 0690 loss_train: 1.1637 acc_train: 0.5920 loss_val: 2.2533 acc_val: 0.5260 time: 9.9748s 0 0\n",
            "Epoch: 0691 loss_train: 1.1162 acc_train: 0.6260 loss_val: 2.2385 acc_val: 0.5260 time: 9.9922s 0 0\n",
            "Epoch: 0692 loss_train: 1.1381 acc_train: 0.6320 loss_val: 2.2345 acc_val: 0.5240 time: 10.0064s 0 0\n",
            "Epoch: 0693 loss_train: 1.1172 acc_train: 0.6540 loss_val: 2.2548 acc_val: 0.5260 time: 10.0199s 0 0\n",
            "Epoch: 0694 loss_train: 1.1450 acc_train: 0.6240 loss_val: 2.2764 acc_val: 0.5260 time: 10.0352s 0 0\n",
            "Epoch: 0695 loss_train: 1.1369 acc_train: 0.6140 loss_val: 2.3018 acc_val: 0.5300 time: 10.0489s 0 0\n",
            "Epoch: 0696 loss_train: 1.1435 acc_train: 0.6080 loss_val: 2.3162 acc_val: 0.5380 time: 10.0641s 0 0\n",
            "Epoch: 0697 loss_train: 1.1661 acc_train: 0.6060 loss_val: 2.3481 acc_val: 0.5360 time: 10.0809s 0 0\n",
            "Epoch: 0698 loss_train: 1.1429 acc_train: 0.5900 loss_val: 2.3920 acc_val: 0.5380 time: 10.0943s 0 0\n",
            "Epoch: 0699 loss_train: 1.1309 acc_train: 0.6360 loss_val: 2.4969 acc_val: 0.5280 time: 10.1076s 0 0\n",
            "Epoch: 0700 loss_train: 1.1351 acc_train: 0.6300 loss_val: 2.4556 acc_val: 0.5200 time: 10.1204s 0 0\n",
            "Epoch: 0701 loss_train: 1.1529 acc_train: 0.6240 loss_val: 2.4880 acc_val: 0.5180 time: 10.1345s 0 0\n",
            "Epoch: 0702 loss_train: 1.1599 acc_train: 0.6200 loss_val: 2.4589 acc_val: 0.5160 time: 10.1488s 0 0\n",
            "Epoch: 0703 loss_train: 1.1579 acc_train: 0.6140 loss_val: 2.5044 acc_val: 0.5100 time: 10.1669s 0 0\n",
            "Epoch: 0704 loss_train: 1.1735 acc_train: 0.5980 loss_val: 2.5670 acc_val: 0.5140 time: 10.1829s 0 0\n",
            "Epoch: 0705 loss_train: 1.1797 acc_train: 0.5940 loss_val: 2.6027 acc_val: 0.5180 time: 10.1988s 0 0\n",
            "Epoch: 0706 loss_train: 1.1449 acc_train: 0.6060 loss_val: 2.6057 acc_val: 0.5200 time: 10.2142s 0 0\n",
            "Epoch: 0707 loss_train: 1.1418 acc_train: 0.6120 loss_val: 2.5796 acc_val: 0.5280 time: 10.2289s 0 0\n",
            "Epoch: 0708 loss_train: 1.1810 acc_train: 0.5840 loss_val: 2.4305 acc_val: 0.5340 time: 10.2459s 0 0\n",
            "Epoch: 0709 loss_train: 1.1758 acc_train: 0.5880 loss_val: 2.2850 acc_val: 0.5280 time: 10.2608s 0 0\n",
            "Epoch: 0710 loss_train: 1.1586 acc_train: 0.6140 loss_val: 2.2846 acc_val: 0.5220 time: 10.2774s 0 0\n",
            "Epoch: 0711 loss_train: 1.1575 acc_train: 0.6220 loss_val: 2.3057 acc_val: 0.5300 time: 10.2930s 0 0\n",
            "Epoch: 0712 loss_train: 1.1481 acc_train: 0.6160 loss_val: 2.3800 acc_val: 0.5220 time: 10.3071s 0 0\n",
            "Epoch: 0713 loss_train: 1.1530 acc_train: 0.6180 loss_val: 2.4774 acc_val: 0.5120 time: 10.3224s 0 0\n",
            "Epoch: 0714 loss_train: 1.1872 acc_train: 0.5880 loss_val: 2.5279 acc_val: 0.5060 time: 10.3360s 0 0\n",
            "Epoch: 0715 loss_train: 1.1835 acc_train: 0.6020 loss_val: 2.6160 acc_val: 0.5100 time: 10.3509s 0 0\n",
            "Epoch: 0716 loss_train: 1.1697 acc_train: 0.5940 loss_val: 2.5874 acc_val: 0.5160 time: 10.3655s 0 0\n",
            "Epoch: 0717 loss_train: 1.1807 acc_train: 0.5840 loss_val: 2.4902 acc_val: 0.5240 time: 10.3839s 0 0\n",
            "Epoch: 0718 loss_train: 1.2088 acc_train: 0.6020 loss_val: 2.3942 acc_val: 0.5320 time: 10.4005s 0 0\n",
            "Epoch: 0719 loss_train: 1.1817 acc_train: 0.5920 loss_val: 2.3066 acc_val: 0.5300 time: 10.4141s 0 0\n",
            "Epoch: 0720 loss_train: 1.1930 acc_train: 0.5840 loss_val: 2.2867 acc_val: 0.5240 time: 10.4282s 0 0\n",
            "Epoch: 0721 loss_train: 1.1703 acc_train: 0.6160 loss_val: 2.3380 acc_val: 0.5200 time: 10.4443s 0 0\n",
            "Epoch: 0722 loss_train: 1.1852 acc_train: 0.5840 loss_val: 2.3118 acc_val: 0.5240 time: 10.4634s 0 0\n",
            "Epoch: 0723 loss_train: 1.1575 acc_train: 0.6120 loss_val: 2.2533 acc_val: 0.5280 time: 10.4793s 0 0\n",
            "Epoch: 0724 loss_train: 1.1487 acc_train: 0.6160 loss_val: 2.1885 acc_val: 0.5240 time: 10.4934s 0 0\n",
            "Epoch: 0725 loss_train: 1.1576 acc_train: 0.6240 loss_val: 2.2028 acc_val: 0.5200 time: 10.5095s 0 0\n",
            "Epoch: 0726 loss_train: 1.1448 acc_train: 0.6160 loss_val: 2.3075 acc_val: 0.5220 time: 10.5255s 0 0\n",
            "Epoch: 0727 loss_train: 1.1563 acc_train: 0.6160 loss_val: 2.4100 acc_val: 0.5400 time: 10.5400s 0 0\n",
            "Epoch: 0728 loss_train: 1.1540 acc_train: 0.6220 loss_val: 2.5105 acc_val: 0.5440 time: 10.5543s 0 0\n",
            "Epoch: 0729 loss_train: 1.2009 acc_train: 0.6120 loss_val: 2.1967 acc_val: 0.5520 time: 10.5701s 0 0\n",
            "Epoch: 0730 loss_train: 1.1330 acc_train: 0.6400 loss_val: 2.1399 acc_val: 0.5400 time: 10.5884s 0 0\n",
            "Epoch: 0731 loss_train: 1.1428 acc_train: 0.6220 loss_val: 2.1202 acc_val: 0.5420 time: 10.6056s 0 0\n",
            "Epoch: 0732 loss_train: 1.0978 acc_train: 0.6280 loss_val: 2.1148 acc_val: 0.5300 time: 10.6199s 0 0\n",
            "Epoch: 0733 loss_train: 1.1704 acc_train: 0.6040 loss_val: 2.1324 acc_val: 0.5140 time: 10.6343s 0 0\n",
            "Epoch: 0734 loss_train: 1.1714 acc_train: 0.5940 loss_val: 2.1463 acc_val: 0.5100 time: 10.6482s 0 0\n",
            "Epoch: 0735 loss_train: 1.1690 acc_train: 0.6260 loss_val: 2.1560 acc_val: 0.5100 time: 10.6621s 0 0\n",
            "Epoch: 0736 loss_train: 1.1906 acc_train: 0.5920 loss_val: 2.1325 acc_val: 0.5200 time: 10.6765s 0 0\n",
            "Epoch: 0737 loss_train: 1.1597 acc_train: 0.6440 loss_val: 2.1380 acc_val: 0.5240 time: 10.6902s 0 0\n",
            "Epoch: 0738 loss_train: 1.1752 acc_train: 0.6040 loss_val: 2.1521 acc_val: 0.5360 time: 10.7035s 0 0\n",
            "Epoch: 0739 loss_train: 1.1288 acc_train: 0.6220 loss_val: 2.1805 acc_val: 0.5400 time: 10.7165s 0 0\n",
            "Epoch: 0740 loss_train: 1.1465 acc_train: 0.6160 loss_val: 2.2142 acc_val: 0.5320 time: 10.7306s 0 0\n",
            "Epoch: 0741 loss_train: 1.1563 acc_train: 0.5940 loss_val: 2.2553 acc_val: 0.5320 time: 10.7446s 0 0\n",
            "Epoch: 0742 loss_train: 1.1445 acc_train: 0.6060 loss_val: 2.5014 acc_val: 0.5380 time: 10.7579s 0 0\n",
            "Epoch: 0743 loss_train: 1.1680 acc_train: 0.6080 loss_val: 2.8159 acc_val: 0.5440 time: 10.7719s 0 0\n",
            "Epoch: 0744 loss_train: 1.1798 acc_train: 0.6020 loss_val: 2.9453 acc_val: 0.5420 time: 10.7849s 0 0\n",
            "Epoch: 0745 loss_train: 1.1781 acc_train: 0.5920 loss_val: 2.8325 acc_val: 0.5340 time: 10.8037s 0 0\n",
            "Epoch: 0746 loss_train: 1.1821 acc_train: 0.5660 loss_val: 2.6020 acc_val: 0.5360 time: 10.8183s 0 0\n",
            "Epoch: 0747 loss_train: 1.1981 acc_train: 0.5740 loss_val: 2.3180 acc_val: 0.5400 time: 10.8318s 0 0\n",
            "Epoch: 0748 loss_train: 1.1963 acc_train: 0.5920 loss_val: 2.1093 acc_val: 0.5380 time: 10.8444s 0 0\n",
            "Epoch: 0749 loss_train: 1.1754 acc_train: 0.6120 loss_val: 2.0525 acc_val: 0.5300 time: 10.8567s 0 0\n",
            "Epoch: 0750 loss_train: 1.1394 acc_train: 0.6100 loss_val: 2.0328 acc_val: 0.5120 time: 10.8702s 0 0\n",
            "Epoch: 0751 loss_train: 1.1732 acc_train: 0.6040 loss_val: 2.0461 acc_val: 0.5120 time: 10.8841s 0 0\n",
            "Epoch: 0752 loss_train: 1.1461 acc_train: 0.6220 loss_val: 2.0983 acc_val: 0.5060 time: 10.8959s 0 0\n",
            "Epoch: 0753 loss_train: 1.1599 acc_train: 0.5900 loss_val: 2.1671 acc_val: 0.5060 time: 10.9086s 0 0\n",
            "Epoch: 0754 loss_train: 1.1998 acc_train: 0.6000 loss_val: 2.3344 acc_val: 0.5260 time: 10.9210s 0 0\n",
            "Epoch: 0755 loss_train: 1.1679 acc_train: 0.6060 loss_val: 2.4778 acc_val: 0.5340 time: 10.9335s 0 0\n",
            "Epoch: 0756 loss_train: 1.1995 acc_train: 0.5940 loss_val: 2.4886 acc_val: 0.5400 time: 10.9465s 0 0\n",
            "Epoch: 0757 loss_train: 1.2078 acc_train: 0.5960 loss_val: 2.4371 acc_val: 0.5320 time: 10.9583s 0 0\n",
            "Epoch: 0758 loss_train: 1.2043 acc_train: 0.6000 loss_val: 2.3744 acc_val: 0.5240 time: 10.9709s 0 0\n",
            "Epoch: 0759 loss_train: 1.1440 acc_train: 0.6300 loss_val: 2.3940 acc_val: 0.5200 time: 10.9835s 0 0\n",
            "Epoch: 0760 loss_train: 1.1474 acc_train: 0.5980 loss_val: 2.5142 acc_val: 0.5240 time: 10.9962s 0 0\n",
            "Epoch: 0761 loss_train: 1.1432 acc_train: 0.6000 loss_val: 2.4552 acc_val: 0.5280 time: 11.0145s 0 0\n",
            "Epoch: 0762 loss_train: 1.1662 acc_train: 0.6220 loss_val: 2.3728 acc_val: 0.5260 time: 11.0278s 0 0\n",
            "Epoch: 0763 loss_train: 1.1327 acc_train: 0.6160 loss_val: 2.3270 acc_val: 0.5240 time: 11.0416s 0 0\n",
            "Epoch: 0764 loss_train: 1.1284 acc_train: 0.6360 loss_val: 2.3424 acc_val: 0.5220 time: 11.0549s 0 0\n",
            "Epoch: 0765 loss_train: 1.1491 acc_train: 0.6000 loss_val: 2.3359 acc_val: 0.5220 time: 11.0689s 0 0\n",
            "Epoch: 0766 loss_train: 1.1586 acc_train: 0.6100 loss_val: 2.2874 acc_val: 0.5240 time: 11.0878s 0 0\n",
            "Epoch: 0767 loss_train: 1.1877 acc_train: 0.5840 loss_val: 2.2791 acc_val: 0.5200 time: 11.1033s 0 0\n",
            "Epoch: 0768 loss_train: 1.1728 acc_train: 0.6060 loss_val: 2.2876 acc_val: 0.5260 time: 11.1158s 0 0\n",
            "Epoch: 0769 loss_train: 1.1321 acc_train: 0.6300 loss_val: 2.2445 acc_val: 0.5320 time: 11.1282s 0 0\n",
            "Epoch: 0770 loss_train: 1.1435 acc_train: 0.6160 loss_val: 2.2202 acc_val: 0.5460 time: 11.1420s 0 0\n",
            "Epoch: 0771 loss_train: 1.1453 acc_train: 0.6000 loss_val: 2.2814 acc_val: 0.5480 time: 11.1548s 0 0\n",
            "Epoch: 0772 loss_train: 1.1693 acc_train: 0.6100 loss_val: 2.3426 acc_val: 0.5460 time: 11.1676s 0 0\n",
            "Epoch: 0773 loss_train: 1.1717 acc_train: 0.6300 loss_val: 2.3839 acc_val: 0.5420 time: 11.1833s 0 0\n",
            "Epoch: 0774 loss_train: 1.1116 acc_train: 0.6360 loss_val: 2.4001 acc_val: 0.5400 time: 11.2003s 0 0\n",
            "Epoch: 0775 loss_train: 1.1180 acc_train: 0.6280 loss_val: 2.4091 acc_val: 0.5420 time: 11.2151s 0 0\n",
            "Epoch: 0776 loss_train: 1.2128 acc_train: 0.6220 loss_val: 2.3636 acc_val: 0.5440 time: 11.2360s 0 0\n",
            "Epoch: 0777 loss_train: 1.1514 acc_train: 0.6340 loss_val: 2.3139 acc_val: 0.5400 time: 11.2504s 0 0\n",
            "Epoch: 0778 loss_train: 1.1366 acc_train: 0.6160 loss_val: 2.2915 acc_val: 0.5340 time: 11.2652s 0 0\n",
            "Epoch: 0779 loss_train: 1.1501 acc_train: 0.6160 loss_val: 2.3158 acc_val: 0.5200 time: 11.2788s 0 0\n",
            "Epoch: 0780 loss_train: 1.0922 acc_train: 0.6280 loss_val: 2.3288 acc_val: 0.5100 time: 11.2931s 0 0\n",
            "Epoch: 0781 loss_train: 1.1053 acc_train: 0.6300 loss_val: 2.3473 acc_val: 0.5100 time: 11.3071s 0 0\n",
            "Epoch: 0782 loss_train: 1.1454 acc_train: 0.6180 loss_val: 2.3383 acc_val: 0.5060 time: 11.3207s 0 0\n",
            "Epoch: 0783 loss_train: 1.1365 acc_train: 0.6080 loss_val: 2.2893 acc_val: 0.5100 time: 11.3342s 0 0\n",
            "Epoch: 0784 loss_train: 1.1365 acc_train: 0.6020 loss_val: 2.2213 acc_val: 0.5180 time: 11.3475s 0 0\n",
            "Epoch: 0785 loss_train: 1.1177 acc_train: 0.6300 loss_val: 2.1872 acc_val: 0.5240 time: 11.3617s 0 0\n",
            "Epoch: 0786 loss_train: 1.1041 acc_train: 0.6260 loss_val: 2.2192 acc_val: 0.5380 time: 11.3753s 0 0\n",
            "Epoch: 0787 loss_train: 1.1190 acc_train: 0.6100 loss_val: 2.2680 acc_val: 0.5420 time: 11.3884s 0 0\n",
            "Epoch: 0788 loss_train: 1.0959 acc_train: 0.6360 loss_val: 2.3206 acc_val: 0.5440 time: 11.4014s 0 0\n",
            "Epoch: 0789 loss_train: 1.1137 acc_train: 0.6300 loss_val: 2.3342 acc_val: 0.5520 time: 11.4157s 0 0\n",
            "Epoch: 0790 loss_train: 1.1226 acc_train: 0.6280 loss_val: 2.3515 acc_val: 0.5580 time: 11.4323s 0 0\n",
            "Epoch: 0791 loss_train: 1.1290 acc_train: 0.6200 loss_val: 2.3682 acc_val: 0.5580 time: 11.4468s 0 0\n",
            "Epoch: 0792 loss_train: 1.0994 acc_train: 0.6380 loss_val: 2.3591 acc_val: 0.5560 time: 11.4625s 0 0\n",
            "Epoch: 0793 loss_train: 1.0911 acc_train: 0.6380 loss_val: 2.3412 acc_val: 0.5400 time: 11.4765s 0 0\n",
            "Epoch: 0794 loss_train: 1.1198 acc_train: 0.6320 loss_val: 2.3245 acc_val: 0.5360 time: 11.4938s 0 0\n",
            "Epoch: 0795 loss_train: 1.1443 acc_train: 0.6160 loss_val: 2.3659 acc_val: 0.5280 time: 11.5077s 0 0\n",
            "Epoch: 0796 loss_train: 1.0928 acc_train: 0.6540 loss_val: 2.3909 acc_val: 0.5340 time: 11.5214s 0 0\n",
            "Epoch: 0797 loss_train: 1.1313 acc_train: 0.6000 loss_val: 2.3640 acc_val: 0.5360 time: 11.5346s 0 0\n",
            "Epoch: 0798 loss_train: 1.1352 acc_train: 0.6300 loss_val: 2.2990 acc_val: 0.5380 time: 11.5484s 0 0\n",
            "Epoch: 0799 loss_train: 1.1284 acc_train: 0.6200 loss_val: 2.2995 acc_val: 0.5440 time: 11.5624s 0 0\n",
            "Epoch: 0800 loss_train: 1.1457 acc_train: 0.6360 loss_val: 2.3045 acc_val: 0.5460 time: 11.5772s 0 0\n",
            "Test set results: loss= 1.8028 accuracy= 0.7528 act_dec_test= -1.0000\n",
            "GCN(\n",
            "  (gc1): GraphConvolution()\n",
            "  (gc2): GraphConvolution()\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Optimization Finished!\n",
            "Total time elapsed: 11.9564s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhEk4gRHSOny"
      },
      "source": [
        "#labels_test_hidden"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyQvWnzSKCDq"
      },
      "source": [
        "#labels_test_hidden[467]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmO9s0xfJ4OQ"
      },
      "source": [
        "#labels_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBmQ-VOGXADS"
      },
      "source": [
        "#labels_test[467]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09oMI4PcWZEf"
      },
      "source": [
        "#labels_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6IMUMXEUMCS"
      },
      "source": [
        "#labels_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r46Svk3DbIpp"
      },
      "source": [
        "#Classify whole graph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoA3OfE3agdf",
        "outputId": "4085111b-ccdd-4e1c-b3e8-399d227e9938"
      },
      "source": [
        "prediction,predicted_output,act_dec = model(features,adj,hidden_labels,-1)\n",
        "\n",
        "acc_all=accuracy(prediction,labels)\n",
        "print(\n",
        "          \"accuracy_Of_Classification= {:.4f}\".format(acc_all.item())\n",
        "        #  ,predicted_output\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy_Of_Classification= 0.7559\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1f3YWI6MUew"
      },
      "source": [
        "predicted_class=[]\n",
        "for i in range(len(labels)):\n",
        "  predicted_class.append(torch.argmax(predicted_output[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-XFQPZjNY9f"
      },
      "source": [
        " predicted_class=torch.LongTensor(predicted_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15pOWgBcx_rl"
      },
      "source": [
        "#prediction[20]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "yP690T9UbrHL",
        "outputId": "f332bad3-5eeb-4182-9f2b-e4742f902c90"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\"Predicted\": predicted_class, \"True\": labels})\n",
        "df=df.loc [df['Predicted']==df['True']]\n",
        "df\n",
        "#df.head(1000)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predicted</th>\n",
              "      <th>True</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13745</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13747</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13748</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13750</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13751</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10395 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Predicted  True\n",
              "0              5     5\n",
              "1              5     5\n",
              "2              9     9\n",
              "4              7     7\n",
              "5              2     2\n",
              "...          ...   ...\n",
              "13745          5     5\n",
              "13747          2     2\n",
              "13748          5     5\n",
              "13750          5     5\n",
              "13751          1     1\n",
              "\n",
              "[10395 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AKDwxIvcl_o",
        "outputId": "bfaf0b54-13a2-48c0-be76-7e128ad0d2f0"
      },
      "source": [
        "df.count()# True prediction out of 13752\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Predicted    10395\n",
              "True         10395\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}